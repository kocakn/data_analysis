{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание : ML как HTTP-сервис\n",
    "\n",
    "## Задача 1: применяем PCA-трансформацию\n",
    "\n",
    "Модифицируйте файл `train.py` - добавьте в пайплайн обучения модели сжатие размерности до `n_components=2` с помощью [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html) и обучите модель **в докере** на \"сжатых\" данных. Сохраните полученный объект `pca_transformer.pkl`, который умеет выполнять сжатие данных.\n",
    "\n",
    "Решением домашки считается модифицированный файл *train.py*\n",
    "\n",
    "[Ссылка на файл train.py](docker_example/train.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Модель обучена! Лог: service.log\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "LOG_FORMAT = '%(asctime)s | %(levelname)-8s | %(filename)-25.25s:%(lineno)-4d | %(message)s'\n",
    "#log_filename = \"/www/classifier/data/service.log\"  # для Docker\n",
    "log_filename = \"service.log\"  # для Jupyter\n",
    "logging.basicConfig(filename=log_filename, level=logging.INFO, format=LOG_FORMAT)\n",
    "\n",
    "# загрузка данных\n",
    "data_source = np.genfromtxt('data/client_segmentation.csv', delimiter=',', skip_header=1)\n",
    "X = data_source[:, :3]\n",
    "y = data_source[:, 3]\n",
    "\n",
    "# сжатие размерности\n",
    "pca = PCA(n_components=2)\n",
    "X = pca.fit_transform(X)\n",
    "\n",
    "# обучение модели\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# сохраняем модель внутри контейнера в директории /www/classifier\n",
    "with open('data/clf.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "    logging.info('Модель обучена и сохранена в %s' % Path().absolute())\n",
    "with open('data/pca_transformer.pkl', 'wb') as f:\n",
    "    pickle.dump(pca, f)\n",
    "    logging.info('Объект для сжатия данных сохранен в %s' % Path().absolute())\n",
    "print(f\"Модель обучена! Лог: {log_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2: трансформация входных фичей на лету\n",
    "\n",
    "Модифицируйте файл `service.py`: добавьте загрузку объекта для трансформации `pca_tansformer.pkl` и применяйте её **в докере** для трансформации набора входных фич в сжатые (см. метод `.transform()`):\n",
    "<pre>\n",
    "[x1, x2, x3] -> [x1_pca, x2_pca]\n",
    "</pre>\n",
    "\n",
    "Соответственно, predict надо выполнять на *сжатых* фичах\n",
    "\n",
    "Решением домашки считается модифицированный файл *service.py*\n",
    "\n",
    "[Ссылка на файл service.py](docker_example/service.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x1': 1.0, 'x2': -2.2, 'x3': 1.05}\n",
      "{'x1_pca': -0.10804973294238474, 'x2_pca': 0.6849826557247147}\n",
      "{'predicted_class': 0}\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# файл, куда посыпятся логи модели\n",
    "LOG_FORMAT = '%(asctime)s | %(levelname)-8s | %(filename)-25.25s:%(lineno)-4d | %(message)s'\n",
    "logging.basicConfig(filename=\"service.log\", level=logging.INFO, format=LOG_FORMAT)\n",
    "\n",
    "\n",
    "def parse_params(params) -> dict:\n",
    "    \"\"\" Получаем и трансформируем параметры \"\"\"\n",
    "    \n",
    "    params_list = params.split('&')\n",
    "    params_dict = {'x1': None, 'x2': None, 'x3': None}\n",
    "    for param in params_list:\n",
    "        key, value = param.split('=')\n",
    "        params_dict[key] = float(value)\n",
    "    print(params_dict)\n",
    "    params_full = np.array(list(params_dict.values()))  # все параметры\n",
    "    params_pca = pca.transform(params_full.reshape(1, -1)).flatten()  # сжимаем до 2 параметров\n",
    "    params_dict_pca = {'x1_pca': params_pca[0], 'x2_pca': params_pca[1]}  # создаем новый словарь\n",
    "    return params_dict_pca\n",
    "\n",
    "\n",
    "logging.info('Загружаем объект для трансформации')\n",
    "with open('data/pca_transformer.pkl', 'rb') as f:\n",
    "    pca = pickle.load(f)\n",
    "    logging.info('Объект загружен: %s' % pca)\n",
    "        \n",
    "logging.info('Загружаем обученную модель')\n",
    "with open('data/clf.pkl', 'rb') as f:\n",
    "    classifier_model = pickle.load(f)\n",
    "    logging.info('Модель загружена: %s' % classifier_model)\n",
    "\n",
    "    \n",
    "params_dict = parse_params('x1=1&x2=-2.2&x3=1.05')\n",
    "print(params_dict)\n",
    "\n",
    "response = params_dict\n",
    "user_features = np.array([params_dict['x1_pca'], params_dict['x2_pca']]).reshape(1, -1)\n",
    "predicted_class = int(classifier_model.predict(user_features)[0])\n",
    "logging.info('predicted_class %s' % predicted_class)\n",
    "print({'predicted_class': predicted_class})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 3: Используем Flask\n",
    "\n",
    "Перепишите сервис на использование Flask. Вы можете взять готовый базовый образ с Flask, либо добавить установку в тот контейнер, который есть - это нужно сделать в Dockerfile\n",
    "\n",
    "Задача необязательная, для успешного выполнения домашки достаточно первых двух пунктов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Выполнение**. Вместо `service.py` был создан файл `app.py`, с использованием Flask для обработки запросов\n",
    "\n",
    "[Ссылка на файл app.py](flask_app/app.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import webbrowser\n",
    "import logging\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "app = Flask(__name__)\n",
    "\n",
    "def load_model():\n",
    "    # файл, куда посыпятся логи модели\n",
    "    LOG_FORMAT = '%(asctime)s | %(levelname)-8s | %(filename)-25.25s:%(lineno)-4d | %(message)s'\n",
    "\n",
    "    logFormatter = logging.Formatter(LOG_FORMAT)\n",
    "    rootLogger = logging.getLogger()\n",
    "\n",
    "    fileHandler = logging.FileHandler(\"service.log\")\n",
    "    fileHandler.setFormatter(logFormatter)\n",
    "    rootLogger.addHandler(fileHandler)\n",
    "\n",
    "    consoleHandler = logging.StreamHandler()\n",
    "    consoleHandler.setFormatter(logFormatter)\n",
    "    rootLogger.addHandler(consoleHandler)\n",
    "\n",
    "    logging.info('Загружаем объект для трансформации')\n",
    "    with open('data/pca_transformer.pkl', 'rb') as f:\n",
    "        pca = pickle.load(f)\n",
    "        logging.info('Объект загружен: %s' % pca)\n",
    "\n",
    "    logging.info('Загружаем обученную модель')\n",
    "    with open('data/clf.pkl', 'rb') as f:\n",
    "        classifier_model = pickle.load(f)\n",
    "        logging.info('Модель загружена: %s' % classifier_model)\n",
    "    return pca, classifier_model\n",
    "\n",
    "def launch_classifier():\n",
    "    param_x1 = (np.random.randint(100) - 50) / 10\n",
    "    param_x2 = (np.random.randint(100) - 50) / 10\n",
    "    param_x3 = (np.random.randint(100) - 50) / 10\n",
    "    params_dict = {'x1': param_x1, 'x2': param_x2, 'x3': param_x3}\n",
    "\n",
    "    pca, classifier_model = load_model()\n",
    "\n",
    "    params_full = np.array(list(params_dict.values()))  # все параметры\n",
    "    params_pca = pca.transform(params_full.reshape(1, -1)).flatten()  # сжимаем до 2 параметров\n",
    "    params_dict_pca = {'x1_pca': params_pca[0], 'x2_pca': params_pca[1]}  # создаем новый словарь\n",
    "    result = params_dict_pca\n",
    "\n",
    "    user_features = np.array([params_dict_pca['x1_pca'], params_dict_pca['x2_pca']]).reshape(1, -1)\n",
    "    predicted_class = int(classifier_model.predict(user_features)[0])\n",
    "    result.update({'predicted_class': predicted_class})\n",
    "    logging.info('predicted_class %s' % predicted_class)\n",
    "    return params_dict, result\n",
    "\n",
    "\n",
    "# @app.route('/ping')\n",
    "def pong_response():\n",
    "    return 'pong'\n",
    "\n",
    "\n",
    "# @app.route('/hello')\n",
    "def hello_world():\n",
    "    return 'Hello, people. Every human is awesome'\n",
    "\n",
    "\n",
    "# @app.route('/english')\n",
    "def english():\n",
    "    return webbrowser.open(\"https://www.youtube.com/watch?v=HbvYeLxMKN8\")\n",
    "\n",
    "\n",
    "# @app.route('/quokka')\n",
    "def quokka_pictures():\n",
    "    return webbrowser.open(\"https://www.instagram.com/explore/tags/quokka/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pong'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pong_response()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier prediction\n",
      "Input variables: x1 = 1.5, x2 = -3.9, x3 = 0.5\n",
      "-----------------------------------\n",
      "x1_pca = -1.051169986974994\n",
      "x2_pca = 0.7724234362960463\n",
      "predicted_class = 0\n"
     ]
    }
   ],
   "source": [
    "input_var, results = launch_classifier()\n",
    "print('Classifier prediction')\n",
    "print(f\"Input variables: x1 = {input_var['x1']}, x2 = {input_var['x2']}, x3 = {input_var['x3']}\")\n",
    "print('-----------------------------------')\n",
    "print(f\"x1_pca = {results['x1_pca']}\")\n",
    "print(f\"x2_pca = {results['x2_pca']}\")\n",
    "print(f\"predicted_class = {results['predicted_class']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание: рекомендательная система\n",
    "\n",
    "## Задача 1: строим KNN\n",
    "\n",
    "В реальной жизни KNN-рекомендатель не стоит делать на основе `sklearn.neighbors.NearestNeighbors` - есть готовые реализации, заточенные специально для построения рекомендательных систем. Хорошим примером такой реализации является [пакет implictit](). В рамках домашней работы предлагается разобраться с реализацией KNN-рекомендателя из этой библиотеки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почитайте документацию по модулю `implicit.nearest_neighbours.CosineRecommender`. Обучите KNN-рекомендатель и воспользуйтесь методом `recommend` для построения рекомендаций\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество просмотров 489565\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>view_duration</th>\n",
       "      <th>view_ts</th>\n",
       "      <th>dt</th>\n",
       "      <th>platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4649</td>\n",
       "      <td>52867</td>\n",
       "      <td>735</td>\n",
       "      <td>2019-03-18 20:40:57+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>48800</td>\n",
       "      <td>361</td>\n",
       "      <td>2019-03-18 11:48:27+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5380</td>\n",
       "      <td>47146</td>\n",
       "      <td>268</td>\n",
       "      <td>2019-02-17 13:06:33+03:00</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4498</td>\n",
       "      <td>30191</td>\n",
       "      <td>297</td>\n",
       "      <td>2019-03-18 15:27:18+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4886</td>\n",
       "      <td>39349</td>\n",
       "      <td>302</td>\n",
       "      <td>2019-03-18 12:08:16+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  content_id  view_duration                   view_ts         dt  \\\n",
       "0     4649       52867            735 2019-03-18 20:40:57+03:00 2019-03-18   \n",
       "1       16       48800            361 2019-03-18 11:48:27+03:00 2019-03-18   \n",
       "2     5380       47146            268 2019-02-17 13:06:33+03:00 2019-02-17   \n",
       "3     4498       30191            297 2019-03-18 15:27:18+03:00 2019-03-18   \n",
       "4     4886       39349            302 2019-03-18 12:08:16+03:00 2019-03-18   \n",
       "\n",
       "  platform  \n",
       "0       LG  \n",
       "1       LG  \n",
       "2       LG  \n",
       "3       LG  \n",
       "4       LG  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import implicit\n",
    "from implicit.nearest_neighbours import CosineRecommender\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "content_views = pd.read_csv(\n",
    "    'recsys_data/content_views.zip', delimiter=',', header=0, compression='zip',\n",
    "    names = ['user_id', 'content_id', 'view_duration', 'view_ts', 'dt', 'platform'],\n",
    "    dtype = {'user_id': np.uint32, 'content_id': np.uint16, 'view_duration': np.uint16},\n",
    "    parse_dates = [3, 4]\n",
    ")\n",
    "print('Количество просмотров %s' % content_views.user_id.count())\n",
    "\n",
    "content_views.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество доступного контента 126182\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>release_date</th>\n",
       "      <th>kinopoisk_rating</th>\n",
       "      <th>compilation_id</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1974</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-15</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2148</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-21</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2184</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-22</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>5.79</td>\n",
       "      <td>121</td>\n",
       "      <td>Романтические</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2463</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2010-01-06</td>\n",
       "      <td>6.80</td>\n",
       "      <td>515</td>\n",
       "      <td>Военные</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_id  origin_country release_date  kinopoisk_rating  compilation_id  \\\n",
       "0        1974            87.0   2009-12-15              7.27             153   \n",
       "1        2148            87.0   2009-12-21              7.27             153   \n",
       "2        2184            87.0   2009-12-22              7.27             153   \n",
       "3        2443             1.0   2010-01-06              5.79             121   \n",
       "4        2463             1.0   2010-01-06              6.80             515   \n",
       "\n",
       "           genre  \n",
       "0      Для детей  \n",
       "1      Для детей  \n",
       "2      Для детей  \n",
       "3  Романтические  \n",
       "4        Военные  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_description = pd.read_csv(\n",
    "    'recsys_data/content_description.zip', delimiter=',', header=0, compression='zip',\n",
    "    names = ['content_id', 'origin_country', 'release_date', 'kinopoisk_rating', 'compilation_id', 'genre'],\n",
    "    dtype = {'content_id': np.uint16},\n",
    "    parse_dates = [2]\n",
    ")\n",
    "print('Количество доступного контента %s' % content_description.content_id.count())\n",
    "content_description.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>view_duration</th>\n",
       "      <th>view_ts</th>\n",
       "      <th>dt</th>\n",
       "      <th>platform</th>\n",
       "      <th>user_index</th>\n",
       "      <th>item_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4649</td>\n",
       "      <td>52867</td>\n",
       "      <td>735</td>\n",
       "      <td>2019-03-18 20:40:57+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>802</td>\n",
       "      <td>22812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>48800</td>\n",
       "      <td>361</td>\n",
       "      <td>2019-03-18 11:48:27+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>2</td>\n",
       "      <td>20399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5380</td>\n",
       "      <td>47146</td>\n",
       "      <td>268</td>\n",
       "      <td>2019-02-17 13:06:33+03:00</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>LG</td>\n",
       "      <td>911</td>\n",
       "      <td>19628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4498</td>\n",
       "      <td>30191</td>\n",
       "      <td>297</td>\n",
       "      <td>2019-03-18 15:27:18+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>773</td>\n",
       "      <td>13517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4886</td>\n",
       "      <td>39349</td>\n",
       "      <td>302</td>\n",
       "      <td>2019-03-18 12:08:16+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>836</td>\n",
       "      <td>16959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  content_id  view_duration                   view_ts         dt  \\\n",
       "0     4649       52867            735 2019-03-18 20:40:57+03:00 2019-03-18   \n",
       "1       16       48800            361 2019-03-18 11:48:27+03:00 2019-03-18   \n",
       "2     5380       47146            268 2019-02-17 13:06:33+03:00 2019-02-17   \n",
       "3     4498       30191            297 2019-03-18 15:27:18+03:00 2019-03-18   \n",
       "4     4886       39349            302 2019-03-18 12:08:16+03:00 2019-03-18   \n",
       "\n",
       "  platform  user_index  item_index  \n",
       "0       LG         802       22812  \n",
       "1       LG           2       20399  \n",
       "2       LG         911       19628  \n",
       "3       LG         773       13517  \n",
       "4       LG         836       16959  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# кодируем индексы пользователей\n",
    "user_encoder = LabelEncoder()\n",
    "user_encoder.fit(content_views.user_id)\n",
    "\n",
    "# переиндексация контента\n",
    "content_views = content_views.assign(\n",
    "    user_index = user_encoder.transform(content_views.user_id)\n",
    ")\n",
    "\n",
    "# кодируем индексы контента\n",
    "item_encoder = LabelEncoder()\n",
    "item_encoder.fit(content_views.content_id)\n",
    "\n",
    "# новая переиндексация\n",
    "content_views = content_views.assign(\n",
    "    item_index = item_encoder.transform(content_views.content_id)\n",
    ")\n",
    "\n",
    "content_views.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.0091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<2000x27012 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 259994 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "num_users = content_views.user_index.max() + 1\n",
    "num_items = content_views.item_index.max() + 1\n",
    "num_interactions = content_views.shape[0]\n",
    "\n",
    "user_item = csr_matrix(\n",
    "    (np.ones(num_interactions),(content_views.user_index.values, content_views.item_index.values)),\n",
    "    shape=(num_users, num_items)\n",
    ")\n",
    "print('sparsity: %.4f' % (num_interactions / (num_users * num_items)))\n",
    "\n",
    "user_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Размер обучающей выборки 1600 пользователей\n",
      "        Размер валидационной выборки 400 пользователей\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ids, test_ids = train_test_split(\n",
    "    np.arange(start=0, stop=user_item.shape[0], step=1, dtype=np.uint32),\n",
    "    test_size=0.2\n",
    ")\n",
    "print(\n",
    "    \"\"\"\n",
    "        Размер обучающей выборки %d пользователей\n",
    "        Размер валидационной выборки %d пользователей\n",
    "    \"\"\"\n",
    "    % (train_ids.size, test_ids.size)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5dc4ff5f0cb4502b088920f64188b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "cos_model = implicit.nearest_neighbours.CosineRecommender()\n",
    "\n",
    "# обучаемся только на тренировочной части пользователей\n",
    "cos_model.fit(user_item[train_ids,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_index 1859, history: [921]\n",
      "recommendations: [(99, 1.0), (600, 1.0), (224, 0.15422992461890894), (782, 0.05992215177119797), (1127, 0.05778319966569877), (511, 0.04296358767810755), (1032, 0.03507153119159472), (1504, 0.030513909884867668), (1280, 0.026171196129510688), (80, 0.02340181886004545)]\n"
     ]
    }
   ],
   "source": [
    "# пример рекомендаций для случайного пользователя\n",
    "random_user_index = np.random.choice(test_ids)\n",
    "random_user_history = user_item.getrow(random_user_index).reshape(1, -1)\n",
    "\n",
    "recs = cos_model.recommend(random_user_index, user_item)\n",
    "print('user_index %d, history: %s' % (random_user_index, random_user_history.nonzero()[1][:10]))\n",
    "print('recommendations: %s' % recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 2: Item to Item\n",
    "\n",
    "Решите задачу c2c рекомендаций - вызовите метод `similar_items` для  *item_id=1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1.0),\n",
       " (437, 0.0756830471617321),\n",
       " (296, 0.07146276141286449),\n",
       " (811, 0.06468462273531508),\n",
       " (242, 0.03593265345403678),\n",
       " (1441, 0.032826608214930636),\n",
       " (224, 0.030845984923781787),\n",
       " (1504, 0.030513909884867668),\n",
       " (568, 0.02918542027088895),\n",
       " (1536, 0.02878368312517019)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related = cos_model.similar_items(itemid=1)\n",
    "related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 3: обучаем Implicit\n",
    "\n",
    "Почитайте документацию по модулю implicit.als.AlternatingLeastSquares. Обучите ALS-рекомендатель и воспользуйтесь методом recommend для построения рекомендаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Intel MKL BLAS detected. Its highly recommend to set the environment variable 'export MKL_NUM_THREADS=1' to disable its internal multithreading\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "716e72d076804ebe97368826911e479c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "als_model = implicit.als.AlternatingLeastSquares()\n",
    "als_model.fit(user_item[train_ids,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_index 114, history: [10390 10725 11615 18698 20928 21733 23009]\n",
      "recommendations: [(614, 0.96021646), (1197, 0.7906255), (530, 0.6134136), (1593, 0.35570723), (1295, 0.30060688), (1430, 0.22426924), (980, 0.15876634), (1132, 0.15178873), (1173, 0.13222319), (1208, 0.12919477)]\n"
     ]
    }
   ],
   "source": [
    "# пример рекомендаций для случайного пользователя\n",
    "random_user_index = np.random.choice(test_ids)\n",
    "random_user_history = user_item.getrow(random_user_index).reshape(1, -1)\n",
    "\n",
    "recs = als_model.recommend(random_user_index, user_item)\n",
    "print('user_index %d, history: %s' % (random_user_index, random_user_history.nonzero()[1][:10]))\n",
    "print('recommendations: %s' % recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 4: реализация метрик\n",
    "\n",
    "Даны два вектора - истинная история пользователя и объекты, которые считает релеватными ваша модель\n",
    "\n",
    "Вычислите\n",
    "\n",
    "* precision\n",
    "* recall\n",
    "* precision@5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.5\n",
      "recall = 0.1\n",
      "average precision at K = 0.012958509750701858\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "user_interactions = [47315, 30004, 36322,  8942, 30820,  6086,  9126,   332, 16289,\n",
    "       39106, 39335, 48506, 48654,  9234, 29935,  2678, 36202, 22636, 18007, 39328, 15414, 30016, 35601,\n",
    "    58409, 21313,   386, 16303, 4397, 19644, 51887, 21659, 36325, 53030,  7764, 50266, 58734, 53419, 24121,\n",
    "    50806, 36092,  8868, 28037, 36131, 13561, 16298, 27508, 41722, 30189, 46490,  2676, 43328, 781, 48397,\n",
    "    41369, 39324, 36381, 39635, 27710, 47837, 28525, 12024, 56604, 41664, 37387, 48507, 413, 33526, 20059,\n",
    "    49781, 56648, 16283, 50805, 34254, 39325, 59374, 22620,  8865, 27512, 13875, 30011,  7621,\n",
    "    10544, 28076, 29716, 30054, 20490, 29466, 16852, 39363, 34250, 7024, 33541,   263, 21267, 25690, 23020,\n",
    "    41368, 53414,  2681, 30201] \n",
    "\n",
    "user_recs = [\n",
    "    50820, 27781, 36131, 50812, 36092, 12024, 59155, 30042, 15414, 19882, 21659, 27849, 39328, 34240, 2681,\n",
    "    21267, 50126, 58560, 7764, 49781\n",
    "]\n",
    "\n",
    "cross = sum(elem in user_recs for elem in user_interactions)\n",
    "precision = cross / len(user_recs)\n",
    "recall = cross / len(user_interactions)\n",
    "print('precision =', precision)\n",
    "print('recall =', recall)\n",
    "\n",
    "apak = 0\n",
    "for index, element in enumerate(user_interactions):\n",
    "    if element in user_recs:\n",
    "        apak += 1 / (index + 1)\n",
    "        \n",
    "apak = apak / len(user_recs)\n",
    "print('average precision at K =', apak)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
