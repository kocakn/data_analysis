{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning в продакшне\n",
    "\n",
    "Поговорим, от том, как выводить модели в продакшн. Вы уже знакомы с понятием \"жизненный цикл ML проекта\" - сегодня мы увидим, как этот цикл выглядит в реальной жизни и попробуем вывести в продакшн модель классификации с помощью технологии виртуализации Docker (можно и без docker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первом уроке мы поговорим о том, как обосновать перед бизнесом необходимость внедрения новой ML-системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оффлайн эксперимент. Proof of concept\n",
    "\n",
    "В рамках курса вы\n",
    "* узнали про огромное количество моделей: классификация, регрессия\n",
    "* научились оценивать качество моделей \n",
    "* можете готовить данные для алгоритмов, включая генерацию фичей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, бизнесу не интересны задачи классификации или регрессии - бизнесу интересно зарабатывать деньги. Чтобы заработать деньги с помощью ML нужно найти конкретную бизнес-проблему, поиском проблем в бизнесе должен заниматься владелец бизнеса (в методологии Agile его зовут Product Owner) и понять, как эту бизнес-проблему можно решить. После такого  начального этапа выявления проблемы бизнес-хотелка отдаётся ML-специалисту, который должен создать инженерное решение для проблемы и интергрировать его в продакшн - после выкатывания прототипа \"в прод\" бизнес начинает зарабатывать миллионы и все счастливы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже я приведу полный путь от бизнес-идеи до прототипа - такой путь проходит любой проект ML, а называют такой пайплайн Proof of concept:\n",
    "\n",
    "1. Перейти от общих слов продукт оунера к конкретным бизнес-требованиям. Желательно, чтобы DS проводил её сам (возможно привлечь бизнес-аналитика).\n",
    "1. Описать дизайн (схему) эксперимента. Нужно понять, как повлиять на бизнес-метрики из первого пункта. На этом этапе нужно понять, какая информация доступна на входе, что ожидается на выходе и к какой задаче ML это можно свести  какие метрики покажут успешность задачи\n",
    "1. Разобраться с данными: где храняться достаточно ли их для проверки гипотезы. Неплохо бы сразу осознать, будут ли данные в продакшене отличаться от того, что доступно в трейне.\n",
    "1. Наинженерить фич и построить модель\n",
    "1. Оценить качество модели, посчитать технические и бизнесовые метрики (см. третий урок)\n",
    "1. Оценить ROI (Return on Investment) — ради этого всё и затевается.\n",
    "\n",
    "Фишка этих шагов в том, что ошибка на любом шаге сильно ухудшает весь проект - например, плохая постановка бизнес-требований приведёт к провальному эксперименту. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчёт ROI - самый важный, финальный этап. Без расчёта эффективности бизнес-заказчик не даст вам добра на выкатывание в продакшн. \n",
    "\n",
    "ROI  — это показатель доходности проекта, равный отношению доходов к затраченным инвестициям. ROI < 100% означает, что проект не окупится.\n",
    "\n",
    "`ROI` = (`LTP`)/(`CL` + `LTL`)\n",
    "\n",
    "1. LTP(Lifetime Profit)  - сколько доходов принесёт проект, пока его не свернут. Вычисляется как *операционные доходы* $\\times$ *срок жизни*\n",
    "1. CL (Capital Loss) - затраты на старт проекта\n",
    "1. LTL(Lifetime Loss)  - сколько расходов принесёт проект, пока его не свернут. Вычисляется как *операционные расходы проекта* $\\times$ *срок жизни проекта*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В капитальные затраты входит закупка железа и лицензий, разработку системы и ее внедрение. Операционные расходы - это то, что тратится на поддержание сервиса: зарплата программистов, devops-инженеров, аренда серверов.\n",
    "\n",
    "Из-за \"мгновенных\" капитальных расходов на старте проекта ROI будет зависеть от времени, на котором мы оцениваем доходность. Обычно для расчета ROI используется один год - нужно понять, окупится проект за год или нет.\n",
    "\n",
    "\n",
    "На далеком горизонте планирования можно окупить любую систему, поэтому важно понять величину *Lifetime* - сколько проработает система "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы узнали, что такое Proof of concept: какие действия нужно произвести чтобы понять, что модель будет полезна и принесёт выгоду. В следующем уроке мы поговорим о метриках сервиса - как понять, что модель действительно работает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики моделей ML\n",
    "\n",
    "Метрики ML-сервисов (как и любых других продакшн-систем) можено разделить на три основных группы\n",
    "\n",
    "* оффлайн-метрики модели\n",
    "* технические метрики сервиса\n",
    "* продуктовые (бизнес) метрики\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оффлайн метрики\n",
    "\n",
    "Оффлайн-метрики показывают, насколько хорошо алгоритм \"выучил\" исторические данные. С этими метриками вы сталкивались в течение всего курса:\n",
    "\n",
    "* RMSE\n",
    "* MAE\n",
    "* precision\n",
    "* recall\n",
    "* accuracy\n",
    "* MAP\n",
    "* $\\ldots$\n",
    "\n",
    "Эти метрики не могут сказать, что модель будет достаточно хороша для бизнеса, но такая модель, как минимум, будет \"не совсем плоха\" чтобы отказываться от её выкатывания в прод. То есть выкатывают модель с хорошими оффлайн метриками и надеются, что она улучшит онлайн-метрики (см. дальше)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В реальной жизни обучение модели запускается регулярно, поэтому оффлайн-метрики нуждаются в мониторинге.\n",
    "\n",
    "Пример из боевой системы обучения моделей: если ROC-AUC падает ниже 0.8, то модель в продакшн не выкатывается, а разработчику приходит уведомление в slack: дружище, с твоей моделью что-то не так, посмотри что случилось:\n",
    "\n",
    "```shell\n",
    "12:11:52,344 | INFO     | hydramatrices_data.py    :65   | Данные из HDFS загружены\n",
    "12:12:10,651 | INFO     | learn2rank_model.py      :168  | Разбили данные на train и test\n",
    "12:13:15,113 | INFO     | learn2rank_model.py      :248  | Кол-во объектов в train 1643676\n",
    "12:14:24,329 | INFO     | learn2rank_model.py      :265  | Новая модель Learning to Rank c2c готова\n",
    "12:14:49,295 | INFO     | learn2rank_model.py      :268  | Train Area under ROC = 0.8517\n",
    "12:15:11,057 | INFO     | learn2rank_model.py      :272  | Test Area under ROC = 0.8516\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Технические метрики\n",
    "\n",
    "Технические метрики сервиса - это некоторые показатели \"здоровья\", железа, которые никак не связаны с логикой\n",
    "\n",
    "* `RPS` (response per second) - сколько запросов в секунду прилетает на сервис\n",
    "* `response time` - время ответа сервиса\n",
    "* `CPU idle` - \"бездействие системы\", чем больше тем лучше. Если падает idle - значит, сильно загружен процессор\n",
    "* `available memory` - сколько памяти доступно на серверах\n",
    "* `500 errors` - количество 500-х ошибок на сервисе\n",
    "\n",
    "Дэшборды с техническими метриками могут выглядеть как-то так:\n",
    "\n",
    "![tech_metrics](img/tech_metrics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сбора и визуализации технических метрик используются следующие инструменты, которые должен знать каждый ML специалист:\n",
    "\n",
    "* statsd - хранение метрик\n",
    "* Grafana - визуализиция графиков\n",
    "* Zabbix - визуализация и отправка уведомлений (например, в slack)\n",
    "* Sentry - для анализа 500-х ошибок\n",
    "* Kibana - логи сервиса\n",
    "\n",
    "Прежде чем катить модель в прод нужно ознакомиться с каждым из этих инструментов и интегрировать с ними свою модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Продуктовые метрики\n",
    "\n",
    "Продуктовые метрики это то, что в первую очередь интересует бизнес. Когда выкатываете новую модель - она должна делать бизнесу лучше, а делать ML ради ML точно не стоит\n",
    "\n",
    "Какие метрики можно улучшить с помощью ML\n",
    "\n",
    "* средний чек\n",
    "* retention - возвращаемость клиентов на сервис\n",
    "* churn - отток клиентов с сервиса\n",
    "* bounce - % пользователей, которые зашли на сервис, но ничего не сделали  (показатель отказов)\n",
    "* конверсия в покупку\n",
    "\n",
    "Проверять, что ваша модель улучшает метрики следует с помощью АБ-теста\n",
    "\n",
    "![ab_testing](img/ab_testing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы узнали, как следить за моделями в продакшн. Вы познакомились с понятием \"технические метрики сервиса\" и теперь знаете, как сделать из \"чёрного ящика\" вашей модели прозрачный и управляемый сервис \n",
    "\n",
    "В следующем уроке мы перейдём к самому интересному - поговорим, как разворачивать модели на боевых серверах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Деплой модели: Docker\n",
    "\n",
    "Этапы разработки прод-сервиса:\n",
    "* разведочный анализ данных\n",
    "* прототип модели в Jupyter\n",
    "* продакшн-сервис\n",
    "\n",
    "Как же перейти от любимого Jupyter ноутбука к продакшин сервису? Современные архитектуры web-проектов предполагают т.н. микросервисную архитектуру, когда для решения конкретной бизнес задачи поднимается маленький веб-сервис, который умеет принимать http-запросы и делать predict, возвращая предсказания в виде json-объекта.\n",
    "\n",
    "JSON - это стадартный формат для общения микросервисов друг с другом, о нём говорили в самом начале курса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![microservices-logical.png](img/microservices-logical.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как упаковать модель в микросервис? Для этого питоновский код нужно обернуть в http-сервер, который будет \"сёрвить\" (обслуживать) http-запросы. Вариантов http-сервера очень много\n",
    "\n",
    "* [Flask](https://palletsprojects.com/p/flask/)\n",
    "* [aiohttp](https://aiohttp.readthedocs.io/en/stable/)\n",
    "* [http.server](https://docs.python.org/3/library/http.server.html)\n",
    "\n",
    "Такой сервис обычно имеет url, на который можно отправлять запросы в заранее определённом формате, например `https://you.service/classify?uid=999` и возвращать ответ в JSON `{'uid': 999, 'class': 1}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При чём тут **Docker**? Докер - это система виртуализации, которая позволяет унифицировать среду разработки и среду выполнения приложения: вы пишете код, который исполняется в виртуальной машине, тестируете его - а потом на боевые сервера отправляется та же самая виртуальная машина."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что вам не нужно волноваться о том, как будет жить питоновский код в продакшне - потому что будет исполняться в той же среде, в которой вы его разрабатывали (и тестировали). Докер является де-факто стандартом в мире современных архитектур для деплоя (т.е. вывода в продакшн-среду) моделей ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простой докер-контейнер\n",
    "\n",
    "Вы уже пользовались докером для разворачивания Postgres базы данных, но не писали своих докерфайлов. Давайте исправим этот факт и напишем простой докер-сервис! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм упаковки сервиса в докер следующий\n",
    "\n",
    "1. Выбрать базовый образ. Я выбрал образ, в который включены такие библиотеки как sklearn, numpy и pandas https://hub.docker.com/r/morpheo/sklearn-base/\n",
    "1. Чтобы докер делал что-то полезное, нужно запустить внутри него программу. Программы внутри контейнера принято запускать через файл `docker-entrypoint.sh`. Для примера я создал файл [simple-entrypoint.sh](docker_example/simple-entrypoint.sh), внутри которого всего одна инструкция `echo \"Hello, MAI!\"`\n",
    "1. Чтобы собрать контейнер, нужно описать его структуру в Dockerfile. Загляните в файл [Dockerfile_simple](docker_example/Dockerfile), где описана структура нашего контейнера\n",
    "\n",
    "```dockerfile\n",
    "FROM morpheo/sklearn-base\n",
    "\n",
    "COPY simple_entrypoint.sh /usr/local/bin/docker-entrypoint.sh\n",
    "RUN chmod +x /usr/local/bin/docker-entrypoint.sh\n",
    "\n",
    "ENTRYPOINT [\"docker-entrypoint.sh\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находясь в директории `docker_example` надо запустить сборку контейнера командой\n",
    "```shell\n",
    "docker build . -f Dockerfile_simple -t mai:simple\n",
    "```\n",
    "\n",
    "После окончания процесса сборки запустить контейнер с помощью инструкции `docker run`:\n",
    "```shell\n",
    "docker run -it --rm  mai:simple\n",
    "```\n",
    "\n",
    "В результате должны увидеть в консоли `Hello, MAI!`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы создали простой контейнер (для понимания), который только и умеет что выводить на печать простую фразу. В следующем уроке мы упакуем в докер пайплайн для тренировки и развёртывания модели машинного обучения в виде http-сервиса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Упаковка модели в Docker: этап research\n",
    "\n",
    "Перед тем, как погружаться в мир докера, создадии пайплайн обучения на python.\n",
    "\n",
    "Начнём с загрузки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call_diff</th>\n",
       "      <th>sms_diff</th>\n",
       "      <th>traffic_diff</th>\n",
       "      <th>customes_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.666421</td>\n",
       "      <td>0.444911</td>\n",
       "      <td>-0.273538</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.889273</td>\n",
       "      <td>-0.537896</td>\n",
       "      <td>-1.959469</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.841503</td>\n",
       "      <td>0.846665</td>\n",
       "      <td>0.727606</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   call_diff  sms_diff  traffic_diff  customes_class\n",
       "0  -0.666421  0.444911     -0.273538             0.0\n",
       "1  -0.889273 -0.537896     -1.959469             2.0\n",
       "2  -0.841503  0.846665      0.727606             0.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_source = pd.read_csv('data/client_segmentation.csv')\n",
    "X = df_source[['call_diff','sms_diff','traffic_diff']].values\n",
    "y = df_source.customes_class.values\n",
    "\n",
    "df_source.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это датасет, в котором три фичи `call_diff`, `sms_diff` и `traffic_diff` которые отражают относительное изменение в объёме звонков, смс и интернет-трафика соответственно по абонентам в базе телеком-оператора и несколько классов клиентов:\n",
    "\n",
    "* класс `0` - пользователь платит много\n",
    "* класс `1` - пользователь платит мало\n",
    "* класс `2` - пользователь ушёл в отток (не платит ничего)\n",
    "\n",
    "От нас требуется обучить модель классификации на три класса. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для визуализации данных выполним понижение размерности с помощью *t-sne*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "\n",
    "x_tsne = TSNE(n_components=2).fit_transform(X)\n",
    "colors = ['bo', 'gx', 'ro']; num_labels = len(colors)\n",
    "# И нарисуем получившиеся точки в нашем новом пространстве\n",
    "for name, label, color in [('class_%d' % i, i, colors[i]) for i in range(num_labels)]:\n",
    "    plt.plot(x_tsne[y == label, 0], x_tsne[y == label, 1], color, label=\"class %d\" % label)\n",
    "plt.legend(loc=0); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бизнесу требуется построить классификатор клиентов - давате обучим простенький классификатор, основанный на решающем дереве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У объекта под номером 36 класс 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# выбираем рандомный объект\n",
    "\n",
    "num_objects = X.shape[0]\n",
    "random_id = np.random.randint(num_objects)\n",
    "\n",
    "# преобразуем фичи, чтобы подошли на вход модели и делаем предсказания\n",
    "test_object = X[random_id,:].reshape(1, -1)\n",
    "pred = clf.predict(test_object)\n",
    "print(f\"У объекта под номером {random_id} класс {pred[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гототово, у нас есть модель, которая что-то обучает и что-то предсказывает. Можем сериализовать её для дальнейшего использования c помощью `pickle`. А теперь попробуем обернуть в докер наш пайплан обучения модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовый контейнер для сервиса я взял отсюда: https://hub.docker.com/r/frolvlad/alpine-python-machinelearning/ . Он включает python 3.5 и библиотеки numpy и sklearn - больше нам для обучения модели ничего не надо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск сборки\n",
    "```shell\n",
    " docker build . -f Dockerfile -t mai:advanced\n",
    "```\n",
    "Запуск обучения модели - см. файл `train.py`\n",
    "```shell\n",
    "docker run -it --rm  -v $(pwd)/data:/www/classifier/data mai:advanced train_model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вся полезная информация отправляется в файл с логами\n",
    "```shell\n",
    "tail -n1 data/service.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример логов модели\n",
    "```shell\n",
    "2020-04-24 06:55:54,070 | INFO     | service.py               :70   | Загружаем обученную модель\n",
    "2020-04-24 06:55:54,071 | INFO     | service.py               :73   | Модель загружена: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=42, splitter='best')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск микросервиса - см. в файле `service.py`\n",
    "```shell\n",
    "docker run -it --rm  -v $(pwd)/data:/www/classifier/data -p 5000:5000 -d mai:advanced start_service\n",
    "```\n",
    "\n",
    "Увидеть запущенный контейнер можно через Docker ps\n",
    "```shell\n",
    "docker ps\n",
    "```\n",
    "\n",
    "Результат команды\n",
    "```shell\n",
    "CONTAINER ID        IMAGE                     COMMAND                  CREATED             STATUS              PORTS                    NAMES\n",
    "c9ba7303712c        mai:advanced   \"docker-entrypoint.s…\"   14 hours ago        Up 14 hours         0.0.0.0:5000->5000/tcp   infallible_easley\n",
    "```\n",
    "\n",
    "Чтобы проверить, что сервис \"жив\" и способен принимать запросы откройте в браузере спициальную страничку `http://0.0.0.0:5000/ping/` - это т.н. *healh check* нашего сервиса. В браузере должно появится\n",
    "```json\n",
    "{\"message\": \"pong\"}\n",
    "```\n",
    "\n",
    "Хороший туториал по [упаковке моделей в контейнеры](https://towardsdatascience.com/deploying-machine-learning-models-with-docker-5d22a4dacb5). Там можно почитать, как скейлить нагрузку помощью nginx+gunikorn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем датасете три фичи - нам нужно передать их в наш микросервис. Передавать фичи можно через GET-запросы, например, так:\n",
    "```url\n",
    "http://0.0.0.0:5000/classifier/?x1=1&x2=-2.2&x3=1.05\n",
    "```\n",
    "\n",
    "Дальше нам нужно перехватить их на стороне сервиса, обработать фичи, загрузив в классификатор и выдать ответ:\n",
    "```json\n",
    "{\"x1\": 1.0, \"x2\": -2.2, \"x3\": 1.05, \"predicted_class\": 0}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После окончания работ контейнер можно остановить\n",
    "```shell\n",
    "docker stop c9ba7303712c\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы упаковали модель в докер и можем использовать модель как микросервис - отправлять запросы и получать предсказания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обобщим все наши знания о микросервисах в одной картинке\n",
    "\n",
    "* у микросервиса должен быть определён формат ответа в виде JSON схемы\n",
    "* Consul - это сервис, который автоматически дёргает *health check* и рестартует контейнер, если он перестал отвечать\n",
    "* блок `logs` - это Elastic+Logstash+Kibana, связка используется для хранения логов\n",
    "* технические метрики отправляются в хранилище Prometheus и визуализируются  в Grafana. Нотификации в случае нештатных ситуаций отправляются в Slack\n",
    "* инциденты в виде 500-х ошибок отправляются в Sentry для дальнейшего анализа\n",
    "\n",
    "![microservice.png](img/microservice.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: применяем PCA-трансформацию\n",
    "\n",
    "[Домашка тут](https://github.com/aleksandr-dzhumurat/data_management/blob/master/jupyter_notebooks/VI_machine_learning_production_hw.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML в проде: рекомендательные системы\n",
    "\n",
    "Рекомендательные системы - это обобщённое название для сервисов, которые в ответ на запрос формируют из огромной коллекции доступных сущностей (мы будем называть их \"документами\", англ. item но в реальной жизни это фильмы в онлайн-кинотеатре или товары в интернет-магазине, а саму такую коллекцию документов для краткости будем называть каталогом) некоторый шорт-лист, который будет наиболее подходящим для данного запроса (такие документы называются \"релевантными\"). Рекомендательные системы используют для решения своих задач другие алгоритмы ML.\n",
    "О том, как на основе уже изученных ML-алгоритмов научиться решать задачу поиска релевантных объектов мы поговорим в этом  уроке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендательные системы: цели и задачи\n",
    "\n",
    "Основная задача рекомендательной системы - нарезать шорт-лист из каталога, который будет максимально подходить к контексту, в котором запрашиваются рекомендации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Под \"контекстом\" мы понимаем различные параметры мира, который окружает рекомендательную систему:\n",
    "\n",
    "* с какими документами из каталога уже взаимодействовал пользователь\n",
    "* какова \"сила\" взаимодействия - лайк или дизлайк? Если оценка - то какая? Если просмотр фильма - то как долго смотрел?\n",
    "* в какой стране находится пользователь - в Казахстане смотрят фильм \"Рэкетир\" а в России \"Бумер\".\n",
    "* утро или вечер в момент посмотрения рекомендаций\n",
    "* что по соцдему - какого пола и возраста пользователь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача рекомендаций представляет собой задачу *ранжирования* - мы пытаемся расставить контент в таком порядке, чтобы в начале списка был самый релевантный контент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот, например, как выглядит главная страница ivi - по сути, это персонализованная нарезка из доступного каталога контента\n",
    "\n",
    "![ivi_main](img/ivi_catalog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Различают два вида рекомендаций:\n",
    "\n",
    "* *content to user*  строятся на основе фидбэка, полученного от пользователя (например, лайкнутые фильмы)\n",
    "* *content to content* строятся на основе свойств контента найти максимально похожие на него элементы (например, блок \"С этим часто покупают\" на Ozon)\n",
    "\n",
    "Рекомендательная система решает задачу персонализации сервиса - это значит, что каждый пользователь  видит свой вариант сервиса - можно сказать, что у вас появляется столько вариантов наполнения страниц вашего сайта, сколько у вас пользователей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендательные системы нужны в ситуации, когда пользователь не может сделать выбор из огромного количества возможных вариантов каталога (например, каталога интернет-магазина) и ему нужно как-то помочь, ограничив выбор узким кругом объектов, которые больше всего подходят к текущему контексту - такие объекты и называются *релевантными*. Избавив пользователя от необходимости просматривать огромное число неподходящих объектов, рекомендательная система позволяет быстрее сконвертировать пользовательскую сессию в \"целевое действие\" - просмотр фильма или покупку гаджета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует два основных метода для поиска релелевантных объектов\n",
    "\n",
    "* collaborative filtering\n",
    "* content filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели *коллаборативной фильтрации* используют интуитивное предположение о том, что если у двух пользователей сильно пересекаются два множества контента (с которым они взаимодействовали) то у этих двух пользователей схожие вкусы - на основе этого можно делать рекомендации. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, у нас есть информация о пользователях `X, Y, Z` и фильмах `A, B, C, D, E`. В таблице символ \"+\" означает, что пользователь $i$ смотрел фильм $j$:\n",
    "\n",
    "| - | A | B | C | D | E |\n",
    "| -- | -- | -- | -- | -- | -- |\n",
    "| X  | +  | -  | +  | +  | -  |\n",
    "| Y  | -  | +  | -  | -  | +  |\n",
    "| Z  | +  | +  | -  | +  | -  |\n",
    "\n",
    "Как видно, пользователи `X, Z` очень похожи друг на друга, т.к. им обоим нравится фильмы \"А\" и \"D\".\n",
    "\n",
    "В то же время пользователь `Y` не похож на них, он смотрит другие фильмы. Из картинки видно, что если бы нам нужно было бы построить персональные рекомендации для пользователя `X`, то мы бы порекомендовали  ему фильм `B` - такой фильм смотрел пользователь Z и значит, этот фильм понравится пользователю X, потому что данные говорят о том, чт вкусы этих двух пользователей похожи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Content-based* фильтрация подбирает похожие элементы на основе свойств контента. Например, в случае фильма его свойства - это актёр, режиссёр, жанр, место действия и т.д. Например, если у нас естьфильм со Стэтхемом, то максимально похожим будет, скорее всего, другой фильм со Стэтхэмом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выделяют *гибридные* рекомендательные системы - в этом случае рекомендации из нескольких моделей (например, `content based` + `collaborative filterig`) используются для формирования итогового ранжирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Колаборативные модели обучаются на триплетах (тройках) `(user, item, feedback)`, где для каждой пары `(user, item)` фидбэк может быть двух видов:\n",
    "\n",
    "* explicit (явный)\n",
    "* implicit (неявный)\n",
    "\n",
    "*Явный фидбэк* - это любое явное выражение пользователем своего отношения к контенту: лайк, оценка и т.д. *Неявный фидбэк* - это длительность просмотра фильма, количество заходов на карточку товара, время чтения статьи и т.д.: интуитивно понятно, что если пользователь смотрит фильм долго - то такой фильм, скорее всего, ему нравится, но явного сигнала (например, в виде лайка) мы не получаем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача построения рекомендации решается с помощью классических алгоритмов машинного обучения:\n",
    "\n",
    "* метод ближайших соседей (knn)\n",
    "* матричная факторизация\n",
    "* логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендатель отдаёт отранжированный список объектов. На этот список обычно накладываются разнообразные бизнес-правила, позволяющие оптимизировать метрики, важные для бизнеса: например, искуственное повышение новинок в выдаче.\n",
    "\n",
    "Грамотно построенная рекомендательная система позволяет нарастить продуктовые метрики. Например, в онлайн-кинотеатре:\n",
    "\n",
    "* растёт конверсия в просмотр т.к. пользователь получает на главной странице самый подходящий контент\n",
    "* увеличивается длительности смотрения на пользователя, удачно рекомендованный сериал генерирует десятки часов смотрения\n",
    "* уменьшается отток с сервиса - пользователь за одну сессию может выбрать несколько фильмов, которые будет смотреть несколько заходов подряд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN рекомендации\n",
    "\n",
    "Мы попробуем построить простейшую модель коллаборативной фильтрации, пользуясь только информацией о просмотрах контента в онлайн-кинотеатре ivi.\n",
    "\n",
    "Загрузим исходные данные - там примерно полмиллиона просмотров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество просмотров 489565\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>view_duration</th>\n",
       "      <th>view_ts</th>\n",
       "      <th>dt</th>\n",
       "      <th>platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4649</td>\n",
       "      <td>52867</td>\n",
       "      <td>735</td>\n",
       "      <td>2019-03-18 20:40:57+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>48800</td>\n",
       "      <td>361</td>\n",
       "      <td>2019-03-18 11:48:27+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5380</td>\n",
       "      <td>47146</td>\n",
       "      <td>268</td>\n",
       "      <td>2019-02-17 13:06:33+03:00</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  content_id  view_duration                   view_ts         dt  \\\n",
       "0     4649       52867            735 2019-03-18 20:40:57+03:00 2019-03-18   \n",
       "1       16       48800            361 2019-03-18 11:48:27+03:00 2019-03-18   \n",
       "2     5380       47146            268 2019-02-17 13:06:33+03:00 2019-02-17   \n",
       "\n",
       "  platform  \n",
       "0       LG  \n",
       "1       LG  \n",
       "2       LG  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "content_views = pd.read_csv(\n",
    "    'recsys_data/content_views.zip', delimiter=',', header=0, compression='zip',\n",
    "    names = ['user_id', 'content_id', 'view_duration', 'view_ts', 'dt', 'platform'],\n",
    "    dtype = {'user_id': np.uint32, 'content_id': np.uint16, 'view_duration': np.uint16},\n",
    "    parse_dates = [3, 4]\n",
    ")\n",
    "\n",
    "\n",
    "print('Количество просмотров %s' % content_views.user_id.count())\n",
    "\n",
    "content_views.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим дополнительную информацию о контенте: жанры, дату появления на сервисе, рейтинг кинопоиска и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество доступного контента 126182\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>release_date</th>\n",
       "      <th>kinopoisk_rating</th>\n",
       "      <th>compilation_id</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1974</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-15</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2148</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-21</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2184</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-22</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_id  origin_country release_date  kinopoisk_rating  compilation_id  \\\n",
       "0        1974            87.0   2009-12-15              7.27             153   \n",
       "1        2148            87.0   2009-12-21              7.27             153   \n",
       "2        2184            87.0   2009-12-22              7.27             153   \n",
       "\n",
       "       genre  \n",
       "0  Для детей  \n",
       "1  Для детей  \n",
       "2  Для детей  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_description = pd.read_csv(\n",
    "    'recsys_data/content_description.zip', delimiter=',', header=0, compression='zip',\n",
    "    names = ['content_id', 'origin_country', 'release_date', 'kinopoisk_rating', 'compilation_id', 'genre'],\n",
    "    dtype = {'content_id': np.uint16},\n",
    "    parse_dates = [2]\n",
    ")\n",
    "\n",
    "print('Количество доступного контента %s' % content_description.content_id.count())\n",
    "\n",
    "content_description.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем разреженную матрицу user-item такую, что\n",
    "\n",
    "* количество строк матрицы совпадает с числом пользователей\n",
    "* количество столбцов матрицы совпадает с количеством контента\n",
    "* на пересечении столбца $i$ и строки $j$ стоит единица, если пользователь $i$ смотрел контент $j$, иначе - ноль\n",
    "\n",
    "Для начала перейдём от индекса контента и индекса пользователя к индексам в разреженной матрице - воспользуемся `LabelEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>view_duration</th>\n",
       "      <th>view_ts</th>\n",
       "      <th>dt</th>\n",
       "      <th>platform</th>\n",
       "      <th>user_index</th>\n",
       "      <th>item_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4649</td>\n",
       "      <td>52867</td>\n",
       "      <td>735</td>\n",
       "      <td>2019-03-18 20:40:57+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>802</td>\n",
       "      <td>22812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>48800</td>\n",
       "      <td>361</td>\n",
       "      <td>2019-03-18 11:48:27+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>2</td>\n",
       "      <td>20399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5380</td>\n",
       "      <td>47146</td>\n",
       "      <td>268</td>\n",
       "      <td>2019-02-17 13:06:33+03:00</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>LG</td>\n",
       "      <td>911</td>\n",
       "      <td>19628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4498</td>\n",
       "      <td>30191</td>\n",
       "      <td>297</td>\n",
       "      <td>2019-03-18 15:27:18+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>773</td>\n",
       "      <td>13517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4886</td>\n",
       "      <td>39349</td>\n",
       "      <td>302</td>\n",
       "      <td>2019-03-18 12:08:16+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>836</td>\n",
       "      <td>16959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  content_id  view_duration                   view_ts         dt  \\\n",
       "0     4649       52867            735 2019-03-18 20:40:57+03:00 2019-03-18   \n",
       "1       16       48800            361 2019-03-18 11:48:27+03:00 2019-03-18   \n",
       "2     5380       47146            268 2019-02-17 13:06:33+03:00 2019-02-17   \n",
       "3     4498       30191            297 2019-03-18 15:27:18+03:00 2019-03-18   \n",
       "4     4886       39349            302 2019-03-18 12:08:16+03:00 2019-03-18   \n",
       "\n",
       "  platform  user_index  item_index  \n",
       "0       LG         802       22812  \n",
       "1       LG           2       20399  \n",
       "2       LG         911       19628  \n",
       "3       LG         773       13517  \n",
       "4       LG         836       16959  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# кодируем индексы пользователей\n",
    "user_encoder = LabelEncoder()\n",
    "user_encoder.fit(content_views.user_id)\n",
    "\n",
    "# переиндексация контента\n",
    "content_views = content_views.assign(\n",
    "    user_index = user_encoder.transform(content_views.user_id)\n",
    ")\n",
    "\n",
    "# кодируем индексы контента\n",
    "item_encoder = LabelEncoder()\n",
    "item_encoder.fit(content_views.content_id)\n",
    "\n",
    "# новая переиндексация\n",
    "content_views = content_views.assign(\n",
    "    item_index = item_encoder.transform(content_views.content_id)\n",
    ")\n",
    "\n",
    "\n",
    "content_views.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть колонки `user_index, item_index`, которые соответствуют номерам строки и столбца соответственно в матрице user-item. Передадим полученные колонки в конструктор `csr_matrix`, чтобы получить разреженную матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.0091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<2000x27012 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 259994 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "num_users = content_views.user_index.max() + 1\n",
    "num_items = content_views.item_index.max() + 1\n",
    "num_interactions = content_views.shape[0]\n",
    "\n",
    "user_item = csr_matrix(\n",
    "    (np.ones(num_interactions),(content_views.user_index.values, content_views.item_index.values)),\n",
    "    shape=(num_users, num_items)\n",
    ")\n",
    "print('sparsity: %.4f' % (num_interactions / (num_users * num_items)))\n",
    "\n",
    "user_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем выборку на валидацию и контроль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Размер обучающей выборки 1600 пользователей\n",
      "        Размер валидационной выборки 400 пользователей\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ids, test_ids = train_test_split(\n",
    "    np.arange(start=0, stop=user_item.shape[0], step=1, dtype=np.uint32),\n",
    "    test_size=0.2\n",
    ")\n",
    "print(\n",
    "    \"\"\"\n",
    "        Размер обучающей выборки %d пользователей\n",
    "        Размер валидационной выборки %d пользователей\n",
    "    \"\"\"\n",
    "    % (train_ids.size, test_ids.size)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что в наше матрице 2000 пользователей и 27012 единиц контента, у матрицы высокая разреженность - менее 1% ненулевых элементов, остальное заполнено нулями.\n",
    "\n",
    "Чтобы строить рекомендации по колаборативной модели, нам нужен быстрый способ поиска пользователей, у которых схожая история просмотров- наше предположение в том, что похожие пользователи имеют похожую историю просмотров. Для поиска схожих пользователей воспользуемся поиском ближайших соседей по нашей матрице `user-item`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine', n_jobs=-1, n_neighbors=20)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "\n",
    "# обучаемся только на тренировочной части пользователей\n",
    "model_knn.fit(user_item[train_ids,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим простейший класс, который умеет искать похожих по истории смотрения пользователей и выдавать рекомендации. Рекомендации - это контент, который смотрели ближашие соседи пользователя, а сам пользователь этот контент не видел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColaborativeFilteringKNNRecommender:\n",
    "    def __init__(self, knn_model, user_item_matrix, num_neighbors):\n",
    "        self.knn_model = knn_model\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.num_neighbors = num_neighbors\n",
    "        self.top_recs = 50\n",
    "    \n",
    "    def make_recs(self, user_history: csr_matrix, top_recs: int):\n",
    "        neighbors = model_knn.kneighbors(\n",
    "            random_user_history,\n",
    "            self.num_neighbors,\n",
    "            return_distance=False\n",
    "        )[0]\n",
    "        full_recs = user_item[neighbors,:].max(axis=0)\n",
    "        # рекомендации - это то, что насмотрели ближайшие соседи\n",
    "        user_history_ids = user_history.nonzero()[1]\n",
    "        # последовательность id того контента, который смотрели ближайшие соседи\n",
    "        full_recs_ids = full_recs.nonzero()[1][:self.top_recs]\n",
    "        # исключаем из рекомендаций то, что уже было у упользователя в историии\n",
    "        success_recs = np.array([i for i in full_recs_ids if i in user_history_ids])\n",
    "        print(\"Число успешных рекомендаций %d из %d\" % (success_recs.size, top_recs))\n",
    "        \n",
    "        return np.array([i for i in full_recs_ids if i not in user_history_ids])[:10]\n",
    "\n",
    "\n",
    "# объект рекомендателя\n",
    "recommender = ColaborativeFilteringKNNRecommender(\n",
    "    knn_model=model_knn,\n",
    "    user_item_matrix=user_item,\n",
    "    num_neighbors=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем рекомендатель для случайного пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число успешных рекомендаций 0 из 10\n",
      "user_index 106, history: [17198 23662]\n",
      "recommendations: [  0   8  76  93  99 141 142 143 144 145]\n"
     ]
    }
   ],
   "source": [
    "# пример рекомендаций для случайного пользователя\n",
    "random_user_index = np.random.choice(test_ids)\n",
    "random_user_history = user_item.getrow(random_user_index).reshape(1, -1)\n",
    "\n",
    "recs = recommender.make_recs(random_user_history, top_recs=10)\n",
    "print('user_index %d, history: %s' % (random_user_index, random_user_history.nonzero()[1][:10]))\n",
    "print('recommendations: %s' % recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашняя работа: строим KNN\n",
    "\n",
    "В реальной жизни KNN-рекомендатель не стоит делать на основе `sklearn.neighbors.NearestNeighbors` - есть готовые реализации, заточенные специально для построения рекомендательных систем. Хорошим примером такой реализации является [пакет implictit](). В рамках домашней работы предлагается разобраться с реализацией KNN-рекомендателя из этой библиотеки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почитайте документацию по модулю `implicit.nearest_neighbours.CosineRecommender`. Обучите KNN-рекомендатель и воспользуйтесь методом `recommend` для построения рекомендаций\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество просмотров 489565\n",
      "Количество доступного контента 126182\n",
      "sparsity: 0.0091\n",
      "Размер обучающей выборки 1600 пользователей\n",
      "Размер валидационной выборки 400 пользователей\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f04956e146426ba8e6ddd9c2bae698",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=1600.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import implicit\n",
    "from implicit.nearest_neighbours import CosineRecommender\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "print('Количество просмотров %s' % content_views.user_id.count())\n",
    "print('Количество доступного контента %s' % content_description.content_id.count())\n",
    "print('sparsity: %.4f' % (num_interactions / (num_users * num_items)))\n",
    "print(\"\"\"Размер обучающей выборки %d пользователей\n",
    "Размер валидационной выборки %d пользователей\"\"\"\n",
    "% (train_ids.size, test_ids.size))\n",
    "cos_model = implicit.nearest_neighbours.CosineRecommender()\n",
    "\n",
    "# обучаемся только на тренировочной части пользователей\n",
    "cos_model.fit(user_item[train_ids,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_index 545, history: [10170]\n",
      "recommendations: [(673, 1.0), (753, 1.0), (1216, 1.0), (1237, 1.0), (886, 1.0), (1318, 1.0), (1540, 1.0), (1401, 1.0), (1579, 1.0), (1215, 1.0)]\n"
     ]
    }
   ],
   "source": [
    "# пример рекомендаций для случайного пользователя\n",
    "random_user_index = np.random.choice(test_ids)\n",
    "random_user_history = user_item.getrow(random_user_index).reshape(1, -1)\n",
    "recs = cos_model.recommend(random_user_index, user_item)\n",
    "print('user_index %d, history: %s' % (random_user_index, random_user_history.nonzero()[1][:10]))\n",
    "print('recommendations: %s' % recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: Item to Item\n",
    "\n",
    "Решите задачу c2c рекомендаций - вызовите метод [similar_items](https://implicit.readthedocs.io/en/latest/models.html?highlight=similar_items#implicit.recommender_base.RecommenderBase.similar_items) для  *item_id=1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1.0),\n",
       " (9, 1.0),\n",
       " (1545, 1.0),\n",
       " (287, 0.7071067811865475),\n",
       " (742, 0.7071067811865475),\n",
       " (1109, 0.7071067811865475),\n",
       " (299, 0.5773502691896258),\n",
       " (1145, 0.059165728513825996),\n",
       " (1505, 0.05347772002957388),\n",
       " (773, 0.035623524993954825)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "related = cos_model.similar_items(itemid=1)\n",
    "related"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы обучили простейшую рекомендательную систему, основанную на колаборативной фильтрации и поиске ближайших соседей. В следующем уроке мы узнаем, как перейти от рекомендаций основанных на knn к более сложной концепции эмбеддингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 3. Эмбеддинги пользователей и контента (скрытые факторы)\n",
    "\n",
    "Рекомендации, которые строятся на основе KNN, имеют следующий недостаток: фактическим мы запоминаем матрицу `user-item` на этапе тренировки модели - такие модели называются *memory-based*. Это привобдит к большому расходу памяти на этапе получения предсказаний, т.к. по каждому пользователю мы вынуждены хранить разреженный вектор большой размерности. При росте количества пользователей модель начинает критически быстро расти по памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой подход заключается в применении матричного разложения - когда мы пытаемся приблизить нашу большую разреженную матрицу user-item размерности $m\\times n$ двумя плотными матрицами, которые называются матрицей латентных (скрытых) факторов пользователей размерности $m\\times f$ и матрицей скрытых факторов контента размерности $n \\times f$. О таких методах мы уже говорили в уроке по теме \"Снижение размерности\" курса \"Машинное обучение. Начальный уровень\". Такой подход, при котором мы запоминаем не матрицу user-item, а только некий полезный сигнал из этой матрицы, называется *model-based*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фокус в том, что $m,n$ - это числа порядка десятков тысяч, а $f$ имеет небольшую размерность (обычно 30-50). Кажому пользователю и каждой единице понтента при таком подходе ставится в соответствие вектор размерности $f$, а произведение вектора пользователя $p_u$ на вектор контента $q_i$ даёт единственное число $r_{ui}$ - меру \"релевантности\", насколько данный контент понравится данному пользователю"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![svd_decomp](img/svd_decomp.png)\n",
    "\n",
    "$$\n",
    "r_{ui} = q_i^Tp_u\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для матричного разложения используются различные алгоритмы:\n",
    "\n",
    "* Singular Vector Decomposition (SVD)\n",
    "* Alternative Least Squares (ALS)\n",
    "* Bayesian personalized ranking (BPR)\n",
    "\n",
    "При решении реальных задач советую начать с BPR - он даёт отличные результаты, но у него есть и недостаток - вычислительная сложность, которая увеличивает время обучения.\n",
    "\n",
    "Выбирая между SVD и ALS я рекомендую выбирать ALS, т.к. он более новый и более быстрый."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы продемонстрируем работу рекомендательной системы на примере SVD-разложения - для этотго даже не нужно устанавливать дополнительные пакеты, нужная функция есть прямо в пакете `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 27012) (2000, 50) (27012, 50)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "latent_factors_num = 50\n",
    "# раскладываем Useк-Item матрицу\n",
    "user_factors, scale, item_factors = svds(\n",
    "    user_item.asfptype(),\n",
    "    k=latent_factors_num,\n",
    "    return_singular_vectors=True\n",
    ")\n",
    "scale = np.diag(np.sqrt(scale))\n",
    "# эмбеддинги пользователей\n",
    "user_factors = np.dot(user_factors, scale).astype(np.float32)\n",
    "# эмбеддинги контента\n",
    "item_factors = np.dot(scale, item_factors).astype(np.float32)\n",
    "\n",
    "print(user_item.shape, user_factors.shape, item_factors.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спроектируем класс, который будет формировать рекомендации на основе матриц `user_factors` и `item_factors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17741, 17745, 17740, 17747, 17744, 17749, 17748, 17743, 22975,\n",
       "       23180, 22973, 23178, 23179, 23181, 22974, 10175, 25196, 12416,\n",
       "       10176], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ColaborativeFilteringFactorizationRecommender:\n",
    "    def __init__(self, user_factors, item_factors, user_item_matrix):\n",
    "        self.user_factors = user_factors\n",
    "        self.item_factors = item_factors\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "    \n",
    "    def make_recs(self, user_index):\n",
    "        user_factors = self.user_factors[user_index,:]\n",
    "        user_history_ids = self.user_item_matrix.getrow(user_index).nonzero()[1]\n",
    "        # рекомендации - это произведение вектора на матрицу\n",
    "        personal_scores = user_factors.reshape(1, -1).dot(self.item_factors).flatten()\n",
    "        personal_recs = np.argsort(-personal_scores)[:20]\n",
    "        \n",
    "        return np.array([i for i in personal_recs if i not in user_history_ids])\n",
    "\n",
    "factorization_recommender = ColaborativeFilteringFactorizationRecommender(\n",
    "    user_factors=user_factors,\n",
    "    item_factors=item_factors,\n",
    "    user_item_matrix=user_item\n",
    ")\n",
    "\n",
    "random_user_index = np.random.choice(test_ids)\n",
    "factorization_recommender.make_recs(random_user_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Колаборативная модель на основе скрытых факторов пользователя/контента позволяет быстро получить список релевантного контента для каждого пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: обучаем Implicit\n",
    "\n",
    "Почитайте документацию по модулю implicit.als.AlternatingLeastSquares. Обучите ALS-рекомендатель и воспользуйтесь методом recommend для построения рекомендаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc45e0dadecf4ed09d285e7f76426751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=15.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "als_model = implicit.als.AlternatingLeastSquares()\n",
    "als_model.fit(user_item[train_ids,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user_index 907, history: [ 79  89  92  94  95  99 271 272 273 274]\n",
      "recommendations: [(27, 0.059524987), (672, 0.059349995), (1504, 0.058182962), (666, 0.05254423), (493, 0.051325392), (960, 0.051096246), (782, 0.05043767), (1047, 0.049249448), (1390, 0.047507647), (1461, 0.046730258)]\n"
     ]
    }
   ],
   "source": [
    "# пример рекомендаций для случайного пользователя\n",
    "random_user_index = np.random.choice(test_ids)\n",
    "random_user_history = user_item.getrow(random_user_index).reshape(1, -1)\n",
    "\n",
    "recs = als_model.recommend(random_user_index, user_item)\n",
    "print('user_index %d, history: %s' % (random_user_index, random_user_history.nonzero()[1][:10]))\n",
    "print('recommendations: %s' % recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этому уроке мы поговорили о том, как перейти от memory-based рекомендателям к model-based. В следующем уроке обсудим, а как измеряют эффективность рекомендательных систем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики рекомендательных систем\n",
    "\n",
    "Мы научились делать персональные рекомендации единиц каталога. В этом уроке поговорим о том, как отделить \"хорошие\" модели от \"плохих\"\n",
    "\n",
    "Метрики рекомендательной системы (как и любых других продакшн-систем) можено разделить на три основных группы\n",
    "\n",
    "* оффлайн-метрики модели\n",
    "* продуктовые (бизнес) метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продуктовые метрики - это то, как пользователи реагируют на рекомендации. К пользовательским метрикам можно отнести:\n",
    "\n",
    "* конверсию (в просмотр, в покупку и т.д.) - чем выше конверсия, тем лучше модель \n",
    "* длительность нахождения на сервисе (чем дольше, тем лучше)\n",
    "* поизицию, до которой были просмотрены рекомендации - чем меньше позиций пролистали, тем лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Продуктовые метрики** (иногда их называют онлайн-метриками) можно измерить, только проведя АБ-тест, эксперимент на реальных пользователях сервиса. Механика проведения эксперимента следующая мы делим пользователей на две группы: группа А видит старый вариант алгоритма, группа Б - новый вариант. После окончания теста сравнивается значение в тестовой группе и контрольной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оффлайн-метрики** рекомендательных систем позволяют проверить, насколько качественные прогнозы выполняет модель, пользуясь историческими данными.\n",
    "\n",
    "Для этой задачи можно приспособить известную Вам метрику **RMSE**, которая определяет, насколько точно мы приблизили матрицу *user-item*\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(a_{ij}-\\hat{a}_{ij})^2}\n",
    "$$\n",
    "\n",
    "Где $a_{ij}$ - истинное значение фидбека пользователя $i$ для контента $j$, а $\\hat{a}_{ij}$ - значение фидбэка, которое предсказала наша модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это неплохая метрика, например, для задачи регрессии, но для рекомендаций она немного странная - в принципе, нам не важно, насколько хорошо предсказываются оценки 2,3,4 - мы хотим уверенном предсказывать высокие оценки: 8,9,10.\n",
    "\n",
    "Другой пример метрик - это метрики из задач классификации (precision + reccall).\n",
    "\n",
    "Допустим, у нас есть список рекомендаций из $n=5$ элементов и список фактических просмотров из $k=3$ элементов. В красную рамку обведены те рекомендации, которые были фактически просмотрены - количество таких фильмов $m = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eval](img/eval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall**  показывает отношение товаров, купленных из рекомендаций к общему числу фактических просмотров\n",
    "\n",
    "$$\n",
    "\\text{recall} = \\frac{m}{k} = \\frac{2}{3}\n",
    "$$\n",
    "\n",
    "**Precision**  показывает, насколько много из рекомендованного нами попало в итоге в просмотренное\n",
    "\n",
    "$$\n",
    "\\text{precision} = \\frac{m}{n} = \\frac{2}{5}\n",
    "$$\n",
    "\n",
    "У precision заметен один недостаток - игнорируется порядок, в котором пользователя заинтересовали рекомендованные объекты. Эту задачу решает метрика *average precision at K*. В числителе дисконтируем каждую \"единичку\", на ту позицию, где она стоит:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{ap} = \\frac{1}{5}\\left( 0 + \\frac{1}{2} + \\frac{1}{3}\\right) = \\frac{1}{5}\\cdot \\frac{5}{6} = \\frac{1}{6}\n",
    "$$\n",
    "\n",
    "при такой модификации мы заставляем модель не просто угадывать релевантные объекты, но и \"поднимать\" их выше к началу списка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме перечисленных выше метрик, которые измеряют точность \"угадывания\", можно мерить и другие показатели\n",
    "\n",
    "* diversity (разннообразие выдачи) - как сильно в выдаче представлены разные жанры, авторы и т.д.\n",
    "* coverage (покарытие каталога) - какая часть каталога покрывается рекомендациями (следует избегать случаев, когда всем пользователям рекомендуюется одно и то же подмножество)\n",
    "* serendipity (индивидуальность) -  берем разницу между вероятностью рекомендации айтема юзеру и всем юзерам (т.е. насколько рекомендация индивидуальна) и суммируем по всем релевантным рекомендованым айтемам. Позволяет определить, насколько выдача \"заточена\" под польователя\n",
    "* novelty (новизна) - как часто попадают в выдачу новые (холодные) элементы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание на метрики\n",
    "\n",
    "Даны два вектора - истинная история пользователя и объекты, которые считает релеватными ваша модель\n",
    "\n",
    "Вычислите\n",
    "\n",
    "* precision\n",
    "* recall\n",
    "* precision@5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.5\n",
      "recall = 0.1\n",
      "average precision at K = 0.012958509750701858\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# просмотры пользователя\n",
    "user_interactions = [47315, 30004, 36322,  8942, 30820,  6086,  9126,   332, 16289,\n",
    "       39106, 39335, 48506, 48654,  9234, 29935,  2678, 36202, 22636, 18007, 39328, 15414, 30016, 35601,\n",
    "    58409, 21313,   386, 16303, 4397, 19644, 51887, 21659, 36325, 53030,  7764, 50266, 58734, 53419, 24121,\n",
    "    50806, 36092,  8868, 28037, 36131, 13561, 16298, 27508, 41722, 30189, 46490,  2676, 43328, 781, 48397,\n",
    "    41369, 39324, 36381, 39635, 27710, 47837, 28525, 12024, 56604, 41664, 37387, 48507, 413, 33526, 20059,\n",
    "    49781, 56648, 16283, 50805, 34254, 39325, 59374, 22620,  8865, 27512, 13875, 30011,  7621,\n",
    "    10544, 28076, 29716, 30054, 20490, 29466, 16852, 39363, 34250, 7024, 33541,   263, 21267, 25690, 23020,\n",
    "    41368, 53414,  2681, 30201] \n",
    "\n",
    "# рекомендации пользователю\n",
    "user_recs = [\n",
    "    50820, 27781, 36131, 50812, 36092, 12024, 59155, 30042, 15414, 19882, 21659, 27849, 39328, 34240, 2681,\n",
    "    21267, 50126, 58560, 7764, 49781\n",
    "]\n",
    "\n",
    "cross = sum(elem in user_recs for elem in user_interactions)\n",
    "precision = cross / len(user_recs)\n",
    "recall = cross / len(user_interactions)\n",
    "print('precision =', precision)\n",
    "print('recall =', recall)\n",
    "\n",
    "apak = 0\n",
    "for index, element in enumerate(user_interactions):\n",
    "    if element in user_recs:\n",
    "        apak += 1 / (index + 1)\n",
    "        \n",
    "apak = apak / len(user_recs)\n",
    "print('average precision at K =', apak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке познакомились с метриками. Теперь вы можете отличать хорошие модели рекомендаций от плохих."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом модуле мы мознакомились с темой рекомендательных систем. Это область знаний, которую \"просто выучить, сложно понять\" - потому что с помощью простых алгоритмов ML можно сильно увеличить эффективность вашего бизнеса, но правильное применение этих методов к задаче построения рекомендательной системы - особое искусство, требующее хорошего понимания бизнес-области и знания специфических метрик систем ранжирования"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
