{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine learning в продакшне\n",
    "\n",
    "Поговорим, от том, как выводить модели в продакшн. Вы уже знакомы с понятием \"жизненный цикл ML проекта\" - сегодня мы увидим, как этот цикл выглядит в реальной жизни и попробуем вывести в продакшн модель классификации с помощью технологии виртуализации Docker (можно и без docker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В первом уроке мы поговорим о том, как обосновать перед бизнесом необходимость внедрения новой ML-системы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оффлайн эксперимент. Proof concept\n",
    "\n",
    "В рамках курса вы\n",
    "* узнали про огромное количество моделей: классификация, регрессия\n",
    "* научились оценивать качество моделей \n",
    "* можете готовить данные для алгоритмов, включая генерацию фичей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Однако, бизнесу не интересны задачи классификации или регрессии - бизнесу интересно зарабатывать деньги. Чтобы заработать деньги с помощью ML нужно найти конкретную бизнес-проблему, поиском проблем в бизнесе должен заниматься владелец бизнеса (в методологии Agile его зовут Product Owner) и понять, как эту бизнес-проблему можно решить. После такого  начального этапа выявления проблемы бизнес-хотелка отдаётся ML-специалисту, который должен создать инженерное решение для проблемы и интергрировать его в продакшн - после выкатывания прототипа \"в прод\" бизнес начинает зарабатывать миллионы и все счастливы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже я приведу полный путь от бизнес-идеи до прототипа - такой путь проходит любой проект ML, а называют такой пайплайн Proof of concect:\n",
    "\n",
    "1. Перейти от общих слов продукт оунера к конкретным бизнес-требованиям. Желательно, чтобы DS проводил её сам (возможно привлечь бизнес-аналитика).\n",
    "1. Описать дизайн (схему) эксперимента. Нужно понять, как повлиять на бизнес-метрики из первого пункта. На этом этапе нужно понять, какая информация доступна на входе, что ожидается на выходе и к какой задаче ML это можно свести  какие метрики покажут успешность задачи\n",
    "1. Разобраться с данными: где храняться достаточно ли их для проверки гипотезы. Неплохо бы сразу осознать, будут ли данные в продакшене отличаться от того, что доступно в трейне.\n",
    "1. Наинженерить фич и построить модель\n",
    "1. Оценить качество модели, посчитать технические и бизнесовые метрики (см. третий урок)\n",
    "1. Оценить ROI (Return on Investment) — ради этого всё и затевается.\n",
    "\n",
    "Фишка этих шагов в том, что ошибка на любом шаге сильно ухудшает весь проект - например, плохая постановка бизнес-требований приведёт к провальному эксперименту. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Расчёт ROI - самый важный, финальный этап. Без расчёта эффективности бизнес-заказчик не даст вам добра на выкатывание в продакшн. \n",
    "\n",
    "ROI  — это показатель доходности проекта, равный отношению доходов к затраченным инвестициям. ROI < 100% означает, что проект не окупится.\n",
    "\n",
    "`ROI` = (`LTP`)/(`CL` + `LTL`)\n",
    "\n",
    "1. LTP(Lifetime Profit)  - сколько доходов принесёт проект, пока его не свернут. Вычисляется как *операционные доходы* $\\times$ *срок жизни*\n",
    "1. CL (Capital Loss) - затраты на старт проекта\n",
    "1. LTL(Lifetime Loss)  - сколько расходов принесёт проект, пока его не свернут. Вычисляется как *операционные расходы проекта* $\\times$ *срок жизни проекта*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В капитальные затраты входит закупка железа и лицензий, разработку системы и ее внедрение. Операционные расходы - это то, что тратится на поддержание сервиса: зарплата программистов, devops-инженеров, аренда серверов.\n",
    "\n",
    "Из-за \"мгновенных\" капитальных расходов на старте проекта ROI будет зависеть от времени, на котором мы оцениваем доходность. Обычно для расчета ROI используется или год - нужно понять, окупится проект за год или нет.\n",
    "\n",
    "\n",
    "На далеком горизонте планирования можно окупить любую систему, поэтому важно понять величину *Lifetime* - сколько проработает система "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы узнали, что такое Proof of concept: какие действия нужно произвести чтобы понять, что модель будет полезна и принесёт выгоду. В следующем уроке мы поговорим о метриках сервиса - как понять, что модель действительно работает"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики моделей ML\n",
    "\n",
    "Метрики ML-сервисов (как и любых других продакшн-систем) можено разделить на три основных группы\n",
    "\n",
    "* оффлайн-метрики модели\n",
    "* технические метрики сервиса\n",
    "* продуктовые (бизнес) метрики\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оффлайн метрики\n",
    "\n",
    "Оффлайн-метрики показывают, насколько хорошо алгоритм \"выучил\" исторические данные. С этими метриками вы сталкивались в течение всего курса:\n",
    "\n",
    "* RMSE\n",
    "* MAE\n",
    "* precision\n",
    "* recall\n",
    "* accuracy\n",
    "* MAP\n",
    "* $\\ldots$\n",
    "\n",
    "Эти метрики не могут сказать, что модель будет достаточно хороша для бизнеса, но такая модель, как минимум, будет \"не совсем плоха\" чтобы отказываться от её выкатывания в прод. То есть выкатывают модель с хорошими оффлайн метриками и надеются, что она улучшит онлайн-метрики (см. дальше)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В реальной жизни обучение модели запускается регулярно, поэтому оффлайн-метрики нуждаются в мониторинге.\n",
    "\n",
    "Пример из боевой системы обучения моделей: если ROC-AUC падает ниже 0.8, то модель в продакшн не выкатывается, а разработчику приходит уведомление в slack: дружище, с твоей моделью что-то не так, посмотри что случилось:\n",
    "\n",
    "<pre>\n",
    "12:11:52,344 | INFO     | hydramatrices_data.py    :65   | Данные из HDFS загружены\n",
    "12:12:10,651 | INFO     | learn2rank_model.py      :168  | Разбили данные на train и test\n",
    "12:13:15,113 | INFO     | learn2rank_model.py      :248  | Кол-во объектов в train 1643676\n",
    "12:14:24,329 | INFO     | learn2rank_model.py      :265  | Новая модель Learning to Rank c2c готова\n",
    "12:14:49,295 | INFO     | learn2rank_model.py      :268  | Train Area under ROC = 0.8517\n",
    "12:15:11,057 | INFO     | learn2rank_model.py      :272  | Test Area under ROC = 0.8516\n",
    "</pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Технические метрики\n",
    "\n",
    "Технические метрики сервиса - это некоторые показатели \"здоровья\", железа, которые никак не связаны с логикой\n",
    "\n",
    "* RPS (response per second) - сколько запросов в секунду прилетает на сервис\n",
    "* response time - время ответа сервиса\n",
    "* CPU idle - \"бездействие системы\", чем больше тем лучше. Если падает idle - значит, сильно загружен процессор\n",
    "* available memory - сколько памяти доступно на серверах\n",
    "* 500 errors - количество 500-х ошибок на сервисе\n",
    "\n",
    "Дэшборды с техническими метриками могут выглядеть как-то так:\n",
    "\n",
    "![tech_metrics](img/tech_metrics.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сбора и визуализации технических метрик используются следующие инструменты, которые должен знать каждый ML специалист:\n",
    "\n",
    "* statsd - хранение метрик\n",
    "* Grafana - визуализиция графиков\n",
    "* Zabbix - визуализация и отправка уведомлений (например, в slack)\n",
    "* Sentry - для анализа 500-х ошибок\n",
    "* Kibana - логи сервиса\n",
    "\n",
    "Прежде чем катить модель в прод нужно ознакомиться с каждым из этих инструментов и интегрировать с ними свою модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Продуктовые метрики\n",
    "\n",
    "Продуктовые метрики это то, что в первую очередь интересует бизнес. Когда выкатываете новую модель - она должна делать бизнесу лучше, а делать ML ради ML точно не стоит\n",
    "\n",
    "Какие метрики можно улучшить с помощью ML\n",
    "\n",
    "* средний чек\n",
    "* retention - возвращаемость клиентов на сервис\n",
    "* churn - отток клиентов с сервиса\n",
    "* bounce - % пользователей, которые зашли на сервис, но ничего не сделали  (показатель отказов)\n",
    "* конверсия в покупку\n",
    "\n",
    "Проверять, что ваша модель улучшает метрики следует с помощью АБ-теста\n",
    "\n",
    "![ab_testing](img/ab_testing.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы узнали, как следить за моделями в продакшн. Вы познакомились с понятием \"технические метрики сервиса\" и теперь знаете, как сделать из \"чёрного ящика\" вашей модели прозрачный и управляемый сервис \n",
    "\n",
    "В следующем уроке мы перейдём к самому интересному - поговорим, как разворачивать модели на боевых серверах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Деплой модели: Docker\n",
    "\n",
    "Этапы разработки прод-сервиса:\n",
    "* разведочный анализ данных\n",
    "* прототип модели в Jupyter\n",
    "* продакшн-сервис\n",
    "\n",
    "Как же перейти от любимого Jupyter ноутбука к продакшин сервису? Современные архитектуры web-проектов предполагают т.н. микросервисную архитектуру, когда для решения конкретной бизнес задачи поднимается маленький веб-сервис, который умеет принимать http-запросы и делать predict, возвращая предсказания в виде json-объекта.\n",
    "\n",
    "JSON - это стадартный формат для общения микросервисов друг с другом, о нём говорили в самом начале курса"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![microservices-logical.png](img/microservices-logical.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как упаковать модель в микросервис? Для этого питоновский код нужно обернуть в http-сервер, который будет \"сёрвить\" (обслуживать) http-запросы. Вариантов http-сервера очень много\n",
    "\n",
    "* [Flask](https://palletsprojects.com/p/flask/)\n",
    "* [aiohttp](https://aiohttp.readthedocs.io/en/stable/)\n",
    "* [http.server](https://docs.python.org/3/library/http.server.html)\n",
    "\n",
    "Такой сервис обычно имеет url, на который можно отправлять запросы в заранее определённом формате, например `https://you.service/classify?uid=999` и возвращать ответ в JSON `{'uid': 999, 'class': 1}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При чём тут Docker? Докер - это система виртуализации, которая позволяет унифицировать среду разработки и среду выполнения приложения: вы пишете код, который исполняется в виртуальной машине, тестируете его - а потом на боевые сервера отправляется та же самая виртуальная машина."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получается, что вам не нужно волноваться о том, как будет жить питоновский код в продакшне - потому что будет исполняться в той же среде, в которой вы его разрабатывали (и тестировали). Докер является де-факто стандартом в мире современных архитектур для деплоя (т.е. вывода в продакшн-среду) моделей ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Простой докер-контейнер\n",
    "\n",
    "Вы уже пользовались докером для разворачивания Postgres базы данных, но не писали своих докерфайлов. Давайте исправим этот факт и напишем простой докер-сервис! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Алгоритм упаковки сервиса в докер следующий\n",
    "\n",
    "1. Выбрать базовый образ. Я выбрал образ, в который включены такие библиотеки как sklearn, numpy и pandas https://hub.docker.com/r/morpheo/sklearn-base/\n",
    "1. Чтобы докер делал что-то полезное, нужно запустить внутри него программу. Программы внутри контейнера принято запускать через файл `docker-entrypoint.sh`. Для примера я создал файл [simple-entrypoint.sh](docker_example/simple-entrypoint.sh), внутри которого всего одна инструкция `echo \"Hello, MAI!\"`\n",
    "1. Чтобы собрать контейнер, нужно описать его структуру в Dockerfile. Загляните в файл [Dockerfile_simple](docker_example/Dockerfile), где описана структура нашего контейнера\n",
    "\n",
    "```dockerfile\n",
    "FROM morpheo/sklearn-base\n",
    "\n",
    "COPY simple_entrypoint.sh /usr/local/bin/docker-entrypoint.sh\n",
    "RUN chmod +x /usr/local/bin/docker-entrypoint.sh\n",
    "\n",
    "ENTRYPOINT [\"docker-entrypoint.sh\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Находясь в директории `docker_example` надо запустить сборку контейнера командой\n",
    "```shell\n",
    "docker build . -f Dockerfile_simple -t mai:simple\n",
    "```\n",
    "\n",
    "После окончания процесса сборки запустить контейнер с помощью инструкции `docker run`:\n",
    "```shell\n",
    "docker run -it --rm  mai:simple\n",
    "```\n",
    "\n",
    "В результате должны увидеть в консоли `Hello, MAI!`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке мы создали простой контейнер (для понимания), который только и умеет что выводить на печать простую фразу. В следующем уроке мы упакуем в докер пайплайн для тренировки и развёртывания модели машинного обучения в виде http-сервиса."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Упаковка модели в Docker\n",
    "\n",
    "Перед тем, как погружаться в мир докера, создадии пайплайн обучения на python.\n",
    "\n",
    "Начнём с загрузки данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call_diff</th>\n",
       "      <th>sms_diff</th>\n",
       "      <th>traffic_diff</th>\n",
       "      <th>customes_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.666421</td>\n",
       "      <td>0.444911</td>\n",
       "      <td>-0.273538</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.889273</td>\n",
       "      <td>-0.537896</td>\n",
       "      <td>-1.959469</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.841503</td>\n",
       "      <td>0.846665</td>\n",
       "      <td>0.727606</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   call_diff  sms_diff  traffic_diff  customes_class\n",
       "0  -0.666421  0.444911     -0.273538             0.0\n",
       "1  -0.889273 -0.537896     -1.959469             2.0\n",
       "2  -0.841503  0.846665      0.727606             0.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df_source = pd.read_csv('data/client_segmentation.csv')\n",
    "X = df_source[['call_diff','sms_diff','traffic_diff']].values\n",
    "y = df_source.customes_class.values\n",
    "\n",
    "df_source.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это датасет, в котором три фичи `call_diff`, `sms_diff` и `traffic_diff` которые отражают относительное изменение в объёме звонков, смс и интернет-трафика соответственно по абонентам в базе телеком-оператора и несколько классов клиентов:\n",
    "\n",
    "* класс `0` - пользователь платит много\n",
    "* класс `1` - пользователь платит мало\n",
    "* класс `2` - пользователь ушёл в отток (не платит ничего)\n",
    "\n",
    "От нас требуется обучить модель классификации на три класса. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для визуализации данных выполним понижение размерности с помощью t-sne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "%matplotlib inline\n",
    "\n",
    "x_tsne = TSNE(n_components=2).fit_transform(X)\n",
    "colors = ['bo', 'gx', 'ro']; num_labels = len(colors)\n",
    "# И нарисуем получившиеся точки в нашем новом пространстве\n",
    "for name, label, color in [('class_%d' % i, i, colors[i]) for i in range(num_labels)]:\n",
    "    plt.plot(x_tsne[y == label, 0], x_tsne[y == label, 1], color, label=\"class %d\" % label)\n",
    "plt.legend(loc=0); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бизнесу требуется построить классификатор клиентов - давате обучим простенький классификатор, основанный на решающем дереве."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "У объекта под номером 95 класс 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "# выбираем рандомный объект\n",
    "\n",
    "num_objects = X.shape[0]\n",
    "random_id = np.random.randint(num_objects)\n",
    "\n",
    "# преобразуем фичи, чтобы подошли на вход модели и делаем предсказания\n",
    "test_object = X[random_id,:].reshape(1, -1)\n",
    "pred = clf.predict(test_object)\n",
    "print(f\"У объекта под номером {random_id} класс {pred[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Гототово, у нас есть модель, которая что-то обучает и что-то предсказывает. Можем сериализовать её для дальнейшего использования c помощью `pickle`. А теперь попробуем обернуть в докер наш пайплан обучения модели. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Базовый контейнер для сервиса я взял отсюда: https://hub.docker.com/r/frolvlad/alpine-python-machinelearning/ . Он включает python 3.5 и библиотеки numpy и sklearn - больше нам для обучения модели ниего не надо."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск сборки\n",
    "```shell\n",
    " docker build . -f Dockerfile -t mai:advanced\n",
    "```\n",
    "Запуск обучения модели - см. файл `train.py`\n",
    "```shell\n",
    "docker run -it --rm  -v $(pwd)/data:/www/classifier/data mai:advanced train_model\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вся полезная информация отправляется в файл с логами\n",
    "```shell\n",
    "tail -n1 data/service.log\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример логов модели\n",
    "```shell\n",
    "2020-04-24 06:55:54,070 | INFO     | service.py               :70   | Загружаем обученную модель\n",
    "2020-04-24 06:55:54,071 | INFO     | service.py               :73   | Модель загружена: DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=3,\n",
    "            max_features=None, max_leaf_nodes=None,\n",
    "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "            presort=False, random_state=42, splitter='best')\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск микросервиса - см. в файле `service.py`\n",
    "```shell\n",
    "docker run -it --rm  -v $(pwd)/data:/www/classifier/data -p 5000:5000 -d mai:advanced start_service\n",
    "```\n",
    "\n",
    "Увидеть запущенный контейнер можно через Docker ps\n",
    "```shell\n",
    "docker ps\n",
    "```\n",
    "\n",
    "Результат команды\n",
    "```shell\n",
    "CONTAINER ID        IMAGE                     COMMAND                  CREATED             STATUS              PORTS                    NAMES\n",
    "c9ba7303712c        mai:advanced   \"docker-entrypoint.s…\"   14 hours ago        Up 14 hours         0.0.0.0:5000->5000/tcp   infallible_easley\n",
    "```\n",
    "\n",
    "Чтобы проверить, что сервис \"жив\" и способен принимать запросы откройте в браузере спициальную страничку `http://0.0.0.0:5000/ping/` - это т.н. *healh check* нашего сервиса. В браузере должно появится\n",
    "```json\n",
    "{\"message\": \"pong\"}\n",
    "```\n",
    "\n",
    "Хороший туториал по [упаковке моделей в контейнеры](https://towardsdatascience.com/deploying-machine-learning-models-with-docker-5d22a4dacb5). Там можно почитать, как скейлить нагрузку помощью nginx+gunikorn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В нашем датасете три фичи - нам нужно передать их в наш микросервис. Передавать фичи можно через GET-запросы, например, так:\n",
    "```url\n",
    "http://0.0.0.0:5000/classifier/?x1=1&x2=-2.2&x3=1.05\n",
    "```\n",
    "\n",
    "Дальше нам нужно перехватить их на стороне сервиса, обработать фичи, загрузив в классификатор и выдать ответ:\n",
    "```json\n",
    "{\"x1\": 1.0, \"x2\": -2.2, \"x3\": 1.05, \"predicted_class\": 0}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "После окончания работ контейнер можно остановить\n",
    "```shell\n",
    "docker stop c9ba7303712c\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы упаковали модель в докер и можем использовать модель как микросервис - отправлять запросы и получать предсказания"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте обобщим все наши знания о микросервисах в одной картинке\n",
    "\n",
    "* у микросервиса должен быть определён формат ответа в виде JSON схемы\n",
    "* Consul - это сервис, который автоматически дёргает *health check* и рестартует контейнер, если он перестал отвечать\n",
    "* блок `logs` - это Elastic+Logstash+Kibana, связка используется для хранения логов\n",
    "* технические метрики отправляются в хранилище Prometheus и визуализируются  в Grafana. Нотификации в случае нештатных ситуаций отправляются в Slack\n",
    "* инциденты в виде 500-х ошибок отправляются в Sentry для дальнейшего анализа\n",
    "\n",
    "![microservice.png](img/microservice.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: применяем t-sne\n",
    "\n",
    "Модифицируйте файл `train.py` - добавьте в пайплайн обучения модели сжатие размерности до `n_components=2` с помощью t-sne и обучите модель **в докере** на \"сжатых\" данных. Сохраните полученный объект `tsne_tansformed_clf.pkl`, который умеет выполнять это задание.\n",
    "\n",
    "Решением домашки считается модифицированный файл *train.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: трансформация входных фичей на лету\n",
    "\n",
    "Модифицируйте файл `service.py`: добавьте загрузку объекта для трансформации `tsne_tansformer.pkl` и применяйте её **в докере** для трансформации набора входных фич в сжатые:\n",
    "<pre>\n",
    "[x1, x2, x3] -> [x1_tsne, x2_tsne]\n",
    "</pre>\n",
    "\n",
    "Соответственно, predict надо выполнять на *сжатых* фичах\n",
    "\n",
    "\n",
    "Решением домашки считается модифицированный файл *service.py*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: Используем Flask\n",
    "\n",
    "Перепишите сервис на использование Flask. Вы можете взять готовый базовый образ с Flask, либо добавить установку в тот контейнер, который есть - это нужно сделать в Dockerfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML в проде: рекомендательные системы\n",
    "\n",
    "Рекомендательные системы - это обобщённое название для сервисов, которые в ответ на запрос формируют из огромной коллекции доступных сущностей (мы будем называть их \"документами\", англ. item но в реальной жизни это фильмы в онлайн-кинотеатре или товары в интернет-магазине, а саму такую коллекцию документов для краткости будем называть каталогом) некоторый шорт-лист, который будет наиболее подходящим для данного запроса (такие документы называются \"релевантными\"). Рекомендательные системы используют для решения своих задач другие алгоритмы ML.\n",
    "О том, как на основе уже изученных ML-алгоритмов научиться решать задачу поиска релевантных объектов мы поговорим в этом  уроке"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Рекомендательные системы: цели и задачи\n",
    "\n",
    "Основная задача рекомендательной системы - нарезать шорт-лист из каталога, который будет максимально подходить к контексту, в котором запрашиваются рекомендации."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Под \"контекстом\" мы понимаем различные параметры мира, который окружает рекомендательную систему:\n",
    "\n",
    "* с какими документами из каталога уже взаимодействовал пользователь\n",
    "* какова \"сила\" взаимодействия - лайк или дизлайк? Если оценка - то какая? Если просмотр фильма - то как долго смотрел?\n",
    "* в какой стране находится пользователь - в Казахстане смотрят фильм \"Рэкетир\" а в России \"Бумер\".\n",
    "* утро или вечер в момент посмотрения рекомендаций\n",
    "* что по соцдему - какого пола и возраста пользователь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача рекомендаций представляет собой задачу *ранжирования* - мы пытаемся расставить контент в таком порядке, чтобы в начале списка был самый релевантный контент"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот, например, как выглядит главная страница ivi - по сути, это персонализованная нарезка из доступного каталога контента\n",
    "\n",
    "![ivi_main](img/ivi_catalog.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Различают два вида рекомендаций:\n",
    "\n",
    "* *content to user*  строятся на основе фидбэка, полученного от пользователя (например, лайкнутые фильмы)\n",
    "* *content to content* строятся на основе свойств контента найти максимально похожие на него элементы (например, блок \"С этим часто покупают\" на Ozon)\n",
    "\n",
    "Рекомендательная система решает задачу персонализации сервиса - это значит, что каждый пользователь  видит свой вариант сервиса - можно сказать, что у вас появляется столько вариантов наполнения страниц вашего сайта, сколько у вас пользователей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендательные системы нужны в ситуации, когда пользователь не может сделать выбор из огромного количества возможных вариантов каталога (например, каталога интернет-магазина) и ему нужно как-то помочь, ограничив выбор узким кругом объектов, которые больше всего подходят к текущему контексту - такие объекты и называются *релевантными*. Избавив пользователя от необходимости просматривать огромное число неподходящих объектов, рекомендательная система позволяет быстрее сконвертировать пользовательскую сессию в \"целевое действие\" - просмотр фильма или покупку гаджета."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Существует два основных метода для поиска релелевантных объектов\n",
    "\n",
    "* collaborative filtering\n",
    "* content filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модели *коллаборативной фильтрации* используют интуитивное предположение о том, что если у двух пользователей сильно пересекаются два множества контента (с которым они взаимодействовали) то у этих двух пользователей схожие вкусы - на основе этого можно делать рекомендации. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Допустим, у нас есть информация о пользователях `X, Y, Z` и фильмах `A, B, C, D, E`. В таблице символ \"+\" означает, что пользователь $i$ смотрел фильм $j$:\n",
    "\n",
    "| - | A | B | C | D | E |\n",
    "| -- | -- | -- | -- | -- | -- |\n",
    "| X  | +  | -  | +  | +  | -  |\n",
    "| Y  | -  | +  | -  | -  | +  |\n",
    "| Z  | +  | +  | -  | +  | -  |\n",
    "\n",
    "Как видно, пользователи `X, Z` очень похожи друг на друга, т.к. им обоим нравится фильмы \"А\" и \"D\".\n",
    "\n",
    "В то же время пользователь `Y` не похож на них, он смотрит другие фильмы. Из картинки видно, что если бы нам нужно было бы построить персональные рекомендации для пользователя `X`, то мы бы порекомендовали  ему фильм `B` - такой фильм смотрел пользователь Z и значит, этот фильм понравится пользователю X, потому что данные говорят о том, чт вкусы этих двух пользователей похожи."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Content-based* фильтрация подбирает похожие элементы на основе свойств контента. Например, в случае фильма его свойства - это актёр, режиссёр, жанр, место действия и т.д. Например, если у нас естьфильм со Стэтхемом, то максимально похожим будет, скорее всего, другой фильм со Стэтхэмом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выделяют *гибридные* рекомендательные системы - в этом случае рекомендации из нескольких моделей (например, `content based` + `collaborative filterig`) используются для формирования итогового ранжирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Колаборативные модели обучаются на триплетах (тройках) `(user, item, feedback)`, где для каждой пары `(user, item)` фидбэк может быть двух видов:\n",
    "\n",
    "* explicit (явный)\n",
    "* implicit (неявный)\n",
    "\n",
    "*Явный фидбэк* - это любое явное выражение пользователем своего отношения к контенту: лайк, оценка и т.д. *Неявный фидбэк* - это длительность просмотра фильма, количество заходов на карточку товара, время чтения статьи и т.д.: интуитивно понятно, что если пользователь смотрит фильм долго - то такой фильм, скорее всего, ему нравится, но явного сигнала (например, в виде лайка) мы не получаем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача построения рекомендации решается с помощью классических алгоритмов машинного обучения:\n",
    "\n",
    "* метод ближайших соседей (knn)\n",
    "* матричная факторизация\n",
    "* логистическая регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рекомендатель отдаёт отранжированный список объектов. На этот список обычно накладываются разнообразные бизнес-правила, позволяющие оптимизировать метрики, важные для бизнеса: например, искуственное повышение новинок в выдаче.\n",
    "\n",
    "Грамотно построенная рекомендательная система позволяет нарастить продуктовые метрики. Например, в онлайн-кинотеатре:\n",
    "\n",
    "* растёт конверсия в просмотр т.к. пользователь получает на главной странице самый подходящий контент\n",
    "* увеличивается длительности смотрения на пользователя, удачно рекомендованный сериал генерирует десятки часов смотрения\n",
    "* уменьшается отток с сервиса - пользователь за одну сессию может выбрать несколько фильмов, которые будет смотреть несколько заходов подряд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN рекомендации\n",
    "\n",
    "Мы попробуем построить простейшую модель коллаборативной фильтрации, пользуясь только информацией о просмотрах контента в онлайн-кинотеатре ivi.\n",
    "\n",
    "Загрузим исходные данные - там примерно полмиллиона просмотров:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество просмотров 489565\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>view_duration</th>\n",
       "      <th>view_ts</th>\n",
       "      <th>dt</th>\n",
       "      <th>platform</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4649</td>\n",
       "      <td>52867</td>\n",
       "      <td>735</td>\n",
       "      <td>2019-03-18 20:40:57+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>48800</td>\n",
       "      <td>361</td>\n",
       "      <td>2019-03-18 11:48:27+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5380</td>\n",
       "      <td>47146</td>\n",
       "      <td>268</td>\n",
       "      <td>2019-02-17 13:06:33+03:00</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>LG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  content_id  view_duration                   view_ts         dt  \\\n",
       "0     4649       52867            735 2019-03-18 20:40:57+03:00 2019-03-18   \n",
       "1       16       48800            361 2019-03-18 11:48:27+03:00 2019-03-18   \n",
       "2     5380       47146            268 2019-02-17 13:06:33+03:00 2019-02-17   \n",
       "\n",
       "  platform  \n",
       "0       LG  \n",
       "1       LG  \n",
       "2       LG  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "content_views = pd.read_csv(\n",
    "    'recsys_data/content_views.zip', delimiter=',', header=0, compression='zip',\n",
    "    names = ['user_id', 'content_id', 'view_duration', 'view_ts', 'dt', 'platform'],\n",
    "    dtype = {'user_id': np.uint32, 'content_id': np.uint16, 'view_duration': np.uint16},\n",
    "    parse_dates = [3, 4]\n",
    ")\n",
    "\n",
    "\n",
    "print('Количество просмотров %s' % content_views.user_id.count())\n",
    "\n",
    "content_views.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим дополнительную информацию о контенте: жанры, дату появления на сервисе, рейтинг кинопоиска и т.д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Количество доступного контента 126182\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content_id</th>\n",
       "      <th>origin_country</th>\n",
       "      <th>release_date</th>\n",
       "      <th>kinopoisk_rating</th>\n",
       "      <th>compilation_id</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1974</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-15</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2148</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-21</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2184</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2009-12-22</td>\n",
       "      <td>7.27</td>\n",
       "      <td>153</td>\n",
       "      <td>Для детей</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   content_id  origin_country release_date  kinopoisk_rating  compilation_id  \\\n",
       "0        1974            87.0   2009-12-15              7.27             153   \n",
       "1        2148            87.0   2009-12-21              7.27             153   \n",
       "2        2184            87.0   2009-12-22              7.27             153   \n",
       "\n",
       "       genre  \n",
       "0  Для детей  \n",
       "1  Для детей  \n",
       "2  Для детей  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_description = pd.read_csv(\n",
    "    'recsys_data/content_description.zip', delimiter=',', header=0, compression='zip',\n",
    "    names = ['content_id', 'origin_country', 'release_date', 'kinopoisk_rating', 'compilation_id', 'genre'],\n",
    "    dtype = {'content_id': np.uint16},\n",
    "    parse_dates = [2]\n",
    ")\n",
    "\n",
    "print('Количество доступного контента %s' % content_description.content_id.count())\n",
    "\n",
    "content_description.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сформируем разреженную матрицу user-item такую, что\n",
    "\n",
    "* количество строк матрицы совпадает с числом пользователей\n",
    "* количество столбцов матрицы совпадает с количеством контента\n",
    "* на пересечении столбца $i$ и строки $j$ стоит единица, если пользователь $i$ смотрел контент $j$, иначе - ноль\n",
    "\n",
    "Для начала перейдём от индекса контента и индекса пользователя к индексам в разреженной матрице - воспользуемся `LabelEncoder`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>content_id</th>\n",
       "      <th>view_duration</th>\n",
       "      <th>view_ts</th>\n",
       "      <th>dt</th>\n",
       "      <th>platform</th>\n",
       "      <th>user_index</th>\n",
       "      <th>item_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4649</td>\n",
       "      <td>52867</td>\n",
       "      <td>735</td>\n",
       "      <td>2019-03-18 20:40:57+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>802</td>\n",
       "      <td>22812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>48800</td>\n",
       "      <td>361</td>\n",
       "      <td>2019-03-18 11:48:27+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>2</td>\n",
       "      <td>20399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5380</td>\n",
       "      <td>47146</td>\n",
       "      <td>268</td>\n",
       "      <td>2019-02-17 13:06:33+03:00</td>\n",
       "      <td>2019-02-17</td>\n",
       "      <td>LG</td>\n",
       "      <td>911</td>\n",
       "      <td>19628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4498</td>\n",
       "      <td>30191</td>\n",
       "      <td>297</td>\n",
       "      <td>2019-03-18 15:27:18+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>773</td>\n",
       "      <td>13517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4886</td>\n",
       "      <td>39349</td>\n",
       "      <td>302</td>\n",
       "      <td>2019-03-18 12:08:16+03:00</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>LG</td>\n",
       "      <td>836</td>\n",
       "      <td>16959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  content_id  view_duration                   view_ts         dt  \\\n",
       "0     4649       52867            735 2019-03-18 20:40:57+03:00 2019-03-18   \n",
       "1       16       48800            361 2019-03-18 11:48:27+03:00 2019-03-18   \n",
       "2     5380       47146            268 2019-02-17 13:06:33+03:00 2019-02-17   \n",
       "3     4498       30191            297 2019-03-18 15:27:18+03:00 2019-03-18   \n",
       "4     4886       39349            302 2019-03-18 12:08:16+03:00 2019-03-18   \n",
       "\n",
       "  platform  user_index  item_index  \n",
       "0       LG         802       22812  \n",
       "1       LG           2       20399  \n",
       "2       LG         911       19628  \n",
       "3       LG         773       13517  \n",
       "4       LG         836       16959  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# кодируем индексы пользователей\n",
    "user_encoder = LabelEncoder()\n",
    "user_encoder.fit(content_views.user_id)\n",
    "\n",
    "# ереиндексация контента\n",
    "content_views = content_views.assign(\n",
    "    user_index = user_encoder.transform(content_views.user_id)\n",
    ")\n",
    "\n",
    "# кодируем индексы контента\n",
    "item_encoder = LabelEncoder()\n",
    "item_encoder.fit(content_views.content_id)\n",
    "\n",
    "# нова переиндексация\n",
    "content_views = content_views.assign(\n",
    "    item_index = item_encoder.transform(content_views.content_id)\n",
    ")\n",
    "\n",
    "\n",
    "content_views.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть колонки `user_index, item_index`, которые соответствуют номерам строки и столбца соответственно в матрице user-item. Передадим полученные колонки в конструктор `csr_matrix`, чтобы получить разреженную матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparsity: 0.0091\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<2000x27012 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 259994 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "num_users = content_views.user_index.max() + 1\n",
    "num_items = content_views.item_index.max() + 1\n",
    "num_interactions = content_views.shape[0]\n",
    "\n",
    "user_item = csr_matrix(\n",
    "    (np.ones(num_interactions),(content_views.user_index.values, content_views.item_index.values)),\n",
    "    shape=(num_users, num_items)\n",
    ")\n",
    "print('sparsity: %.4f' % (num_interactions / (num_users * num_items)))\n",
    "\n",
    "user_item"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделяем выборку на валидацию и контроль"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер обучающей выборки 1600 пользователей, размер валидационной выборки 400 пользователей\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_ids, test_ids = train_test_split(\n",
    "    np.arange(start=0, stop=user_item.shape[0], step=1, dtype=np.uint32),\n",
    "    test_size=0.2\n",
    ")\n",
    "print(\n",
    "    \"Размер обучающей выборки %d пользователей, размер валидационной выборки %d пользователей\"\n",
    "    % (train_ids.size, test_ids.size)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы видим, что в наше матрице 2000 пользователей и 27012 единиц контента, у матрицы высокая разреженность - менее 1% ненулевых элементов, остальное заполнено нулями.\n",
    "\n",
    "Чтобы строить рекомендации по колаборативной модели, нам нужен быстрый способ поиска пользователей, у которых схожая история просмотров- наше предположение в том, что похожие пользователи имеют похожую историю просмотров. Для поиска схожих пользователей воспользуемся поиском ближайших соседей по нашей матрице `user-item`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', leaf_size=30, metric='cosine',\n",
       "                 metric_params=None, n_jobs=-1, n_neighbors=20, p=2,\n",
       "                 radius=1.0)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "model_knn = NearestNeighbors(metric='cosine', algorithm='brute', n_neighbors=20, n_jobs=-1)\n",
    "\n",
    "# обучаемся только на тренировочной части пользователей\n",
    "model_knn.fit(user_item[train_ids,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим простейший класс, который умеет искать похожих по истории смотрения пользователей и выдавать рекомендации. Рекомендации - это контент, который смотрели ближашие соседи пользователя, а сам пользователь этот контент не видел"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ColaborativeFilteringKNNRecommender:\n",
    "    def __init__(self, knn_model, user_item_matrix, num_neighbors):\n",
    "        self.knn_model = knn_model\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "        self.num_neighbors = num_neighbors\n",
    "        self.top_recs = 50\n",
    "    \n",
    "    def make_recs(self, user_history: csr_matrix, top_recs: int):\n",
    "        neighbors = model_knn.kneighbors(\n",
    "            random_user_history,\n",
    "            self.num_neighbors,\n",
    "            return_distance=False\n",
    "        )[0]\n",
    "        full_recs = user_item[neighbors,:].max(axis=0)\n",
    "        # рекомендации - это то, что насмотрели ближайшие соседи\n",
    "        user_history_ids = user_history.nonzero()[1]\n",
    "        # последовательность id того контента, который смотрели ближайшие соседи\n",
    "        full_recs_ids = full_recs.nonzero()[1][:self.top_recs]\n",
    "        # исключаем из рекомендаций то, что уже было у упользователя в историии\n",
    "        success_recs = np.array([i for i in full_recs_ids if i in user_history_ids])\n",
    "        print(\"Число успешных рекомендаций %d из %d\" % (success_recs.size, top_recs))\n",
    "        \n",
    "        return np.array([i for i in full_recs_ids if i not in user_history_ids])[:10]\n",
    "\n",
    "\n",
    "# объект рекомендателя\n",
    "recommender = ColaborativeFilteringKNNRecommender(\n",
    "    knn_model=model_knn,\n",
    "    user_item_matrix=user_item,\n",
    "    num_neighbors=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Применяем рекомендатель для случайного пользователя"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число успешных рекомендаций 6 из 10\n",
      "user_index 954, history: [   9   76  939  940  983 1086 1087 1088 1089 1090]\n",
      "recommendations: [ 687  988 1250 1254 1295 1300 1303 1307 1416 1500]\n"
     ]
    }
   ],
   "source": [
    "# пример рекомендаций для случайного пользователя\n",
    "random_user_index = np.random.choice(test_ids)\n",
    "random_user_history = user_item.getrow(random_user_index).reshape(1, -1)\n",
    "\n",
    "recs = recommender.make_recs(random_user_history, top_recs=10)\n",
    "print('user_index %d, history: %s' % (random_user_index, random_user_history.nonzero()[1][:10]))\n",
    "print('recommendations: %s' % recs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Домашняя работа: строим KNN\n",
    "\n",
    "В реальной жизни KNN-рекомендатель не стоит делать на основе `sklearn.neighbors.NearestNeighbors` - есть готовые реализации, заточенные специально для построения рекомендательных систем. Хорошим примером такой реализации является [пакет implictit](). В рамках домашней работы предлагается разобраться с реализацией KNN-рекомендателя из этой библиотеки "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Почитайте документацию по модулю `implicit.nearest_neighbours.CosineRecommender`. Обучите KNN-рекомендатель и воспользуйтесь методом `recommend` для построения рекомендаций\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: Item to Item\n",
    "\n",
    "Решите задачу c2c рекомендаций - вызовите метод `similar_items` для  *item_id=1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "# ------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы обучили простейшую рекомендательную систему, основанную на колаборативной фильтрации и поиске ближайших соседей. В следующем уроке мы узнаем, как перейти от рекомендаций основанных на knn к более сложной концепции эмбеддингов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Урок 3. Эмбеддинги пользователей и контента (скрытые факторы)\n",
    "\n",
    "Рекомендации, которые строятся на основе KNN, имеют следующий недостаток: фактическим мы запоминаем матрицу `user-item` на этапе тренировки модели - такие модели называются *memory-based*. Это привобдит к большому расходу памяти на этапе получения предсказаний, т.к. по каждому пользователю мы вынуждены хранить разреженный вектор большой размерности. При росте количества пользователей модель начинает критически быстро расти по памяти."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Другой подход заключается в применении матричного разложения - когда мы пытаемся приблизить нашу большую разреженную матрицу user-item размерности $m\\times n$ двумя плотными матрицами, которые называются матрицей латентных (скрытых) факторов пользователей размерности $m\\times f$ и матрицей скрытых факторов контента размерности $n \\times f$. О таких методах мы уже говорили в уроке по теме \"Снижение размерности\" курса \"Машинное обучение. Начальный уровень\". Такой подход, при котором мы запоминаем не матрицу user-item, а только некий полезный сигнал из этой матрицы, называется *model-based*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Фокус в том, что $m,n$ - это числа порядка десятков тысяч, а $f$ имеет небольшую размерность (обычно 30-50). Кажому пользователю и каждой единице понтента при таком подходе ставится в соответствие вектор размерности $f$, а произведение вектора пользователя $p_u$ на вектор контента $q_i$ даёт единственное число $r_{ui}$ - меру \"релевантности\", насколько данный контент понравится данному пользователю"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![svd_decomp](img/svd_decomp.png)\n",
    "\n",
    "$$\n",
    "r_{ui} = q_i^Tp_u\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для матричного разложения используются различные алгоритмы:\n",
    "\n",
    "* Singular Vector Decomposition (SVD)\n",
    "* Alternative Least Squares (ALS)\n",
    "* Bayesian personalized ranking (BPR)\n",
    "\n",
    "При решении реальных задач советую начать с BPR - он даёт отличные результаты, но у него есть и недостаток - вычислительная сложность, которая увеличивает время обучения.\n",
    "\n",
    "Выбирая между SVD и ALS я рекомендую выбирать ALS, т.к. он более новый и более быстрый."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы продемонстрируем работу рекомендательной системы на примере SVD-разложения - для этотго даже не нужно устанавливать дополнительные пакеты, нужная функция есть прямо в пакете `numpy`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 27012) (2000, 50) (27012, 50)\n"
     ]
    }
   ],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "latent_factors_num = 50\n",
    "# раскладываем Useк-Item матрицу\n",
    "user_factors, scale, item_factors = svds(\n",
    "    user_item.asfptype(),\n",
    "    k=latent_factors_num,\n",
    "    return_singular_vectors=True\n",
    ")\n",
    "scale = np.diag(np.sqrt(scale))\n",
    "# эмбеддинги пользователей\n",
    "user_factors = np.dot(user_factors, scale).astype(np.float32)\n",
    "# эмбеддинги контента\n",
    "item_factors = np.dot(scale, item_factors).astype(np.float32)\n",
    "\n",
    "print(user_item.shape, user_factors.shape, item_factors.T.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Спроектируем класс, который будет формировать рекомендации на основе матриц `user_factors` и `item_factors`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16421,  8459, 15912, 17787, 23459, 26717,  2484, 13301, 13309,\n",
       "       23456, 13344,   603])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ColaborativeFilteringFactorizationRecommender:\n",
    "    def __init__(self, user_factors, item_factors, user_item_matrix):\n",
    "        self.user_factors = user_factors\n",
    "        self.item_factors = item_factors\n",
    "        self.user_item_matrix = user_item_matrix\n",
    "    \n",
    "    def make_recs(self, user_index):\n",
    "        user_factors = self.user_factors[user_index,:]\n",
    "        user_history_ids = self.user_item_matrix.getrow(user_index).nonzero()[1]\n",
    "        # рекомендации - это произведение вектора на матрицу\n",
    "        personal_scores = user_factors.reshape(1, -1).dot(self.item_factors).flatten()\n",
    "        personal_recs = np.argsort(-personal_scores)[:20]\n",
    "        \n",
    "        return np.array([i for i in personal_recs if i not in user_history_ids])\n",
    "\n",
    "factorization_recommender = ColaborativeFilteringFactorizationRecommender(\n",
    "    user_factors=user_factors,\n",
    "    item_factors=item_factors,\n",
    "    user_item_matrix=user_item\n",
    ")\n",
    "\n",
    "random_user_index = np.random.choice(test_ids)\n",
    "factorization_recommender.make_recs(random_user_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Колаборативная модель на основе скрытых факторов пользователя/контента позволяет быстро получить список релевантного контента для каждого пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание: обучаем Implicit\n",
    "\n",
    "Почитайте документацию по модулю implicit.als.AlternatingLeastSquares. Обучите ALS-рекомендатель и воспользуйтесь методом recommend для построения рекомендаций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- ВАШ КОД ТУТ --\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# -----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этому уроке мы поговорили о том, как перейти от memory-based рекомендателям к model-based. В следующем уроке обсудим, а как измеряют эффективность рекомендательных систем."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Метрики рекомендательных систем\n",
    "\n",
    "Мы научились делать персональные рекомендации единиц каталога. В этом уроке поговорим о том, как отделить \"хорошие\" модели от \"плохих\"\n",
    "\n",
    "Метрики рекомендательной системы (как и любых других продакшн-систем) можено разделить на три основных группы\n",
    "\n",
    "* оффлайн-метрики модели\n",
    "* продуктовые (бизнес) метрики"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продуктовые метрики - это то, как пользователи реагируют на рекомендации. К пользовательским метрикам можно отнести:\n",
    "\n",
    "* конверсию (в просмотр, в покупку и т.д.) - чем выше конверсия, тем лучше модель \n",
    "* длительность нахождения на сервисе (чем дольше, тем лучше)\n",
    "* поизицию, до которой были просмотрены рекомендации - чем меньше позиций пролистали, тем лучше"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Продуктовые метрики** (иногда их называют онлайн-метриками) можно измерить, только проведя АБ-тест, эксперимент на реальных пользователях сервиса. Механика проведения эксперимента следующая мы делим пользователей на две группы: группа А видит старый вариант алгоритма, группа Б - новый вариант. После окончания теста сравнивается значение в тестовой группе и контрольной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Оффлайн-метрики** рекомендательных систем позволяют проверить, насколько качественные прогнозы выполняет модель, пользуясь историческими данными.\n",
    "\n",
    "Для этой задачи можно приспособить известную Вам метрику **RMSE**, которая определяет, насколько точно мы приблизили матрицу *user-item*\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(a_{ij}-\\hat{a}_{ij})^2}\n",
    "$$\n",
    "\n",
    "Где $a_{ij}$ - истинное значение фидбека пользователя $i$ для контента $j$, а $\\hat{a}_{ij}$ - значение фидбэка, которое предсказала наша модель"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это неплохая метрика, например, для задачи регрессии, но для рекомендаций она немного странная - в принципе, нам не важно, насколько хорошо предсказываются оценки 2,3,4 - мы хотим уверенном предсказывать высокие оценки: 8,9,10.\n",
    "\n",
    "Другой пример метрик - это метрики из задач классификации (precision + reccall).\n",
    "\n",
    "Допустим, у нас есть список рекомендаций из $n=5$ элементов и список фактических просмотров из $k=3$ элементов. В красную рамку обведены те рекомендации, которые были фактически просмотрены - количество таких фильмов $m = 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eval](img/eval.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Recall**  показывает отношение товаров, купленных из рекомендаций к общему числу фактических просмотров\n",
    "\n",
    "$$\n",
    "\\text{recall} = \\frac{m}{k} = \\frac{2}{3}\n",
    "$$\n",
    "\n",
    "**Precision**  показывает, насколько много из рекомендованного нами попало в итоге в просмотренное\n",
    "\n",
    "$$\n",
    "\\text{precision} = \\frac{m}{n} = \\frac{2}{5}\n",
    "$$\n",
    "\n",
    "У precision заметен один недостаток - игнорируется порядок, в котором пользователя заинтересовали рекомендованные объекты. Эту задачу решает метрика *average precision at K*. В числителе дисконтируем каждую \"единичку\", на ту позицию, где она стоит:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{ap} = \\frac{1}{5}\\left( 0 + \\frac{1}{2} + \\frac{1}{3}\\right) = \\frac{1}{5}\\cdot \\frac{5}{6} = \\frac{1}{6}\n",
    "$$\n",
    "\n",
    "при такой модификации мы заставляем модель не просто угадывать релевантные объекты, но и \"поднимать\" их выше к началу списка"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кроме перечисленных выше метрик, которые измеряют точность \"угадывания\", можно мерять и другие показатели\n",
    "\n",
    "* diversity (разннообразие выдачи) - как сильно в выдаче представлены разные жанры, авторы и т.д.\n",
    "* coverage (покарытие каталога) - какая часть каталога покрывается рекомендациями (следует избегать случаев, когда всем пользователям рекомендуюется одно и то же подмножество)\n",
    "* serendipity (индивидуальность) -  берем разницу между вероятностью рекомендации айтема юзеру и всем юзерам (т.е. насколько рекомендация индивидуальна) и суммируем по всем релевантным рекомендованым айтемам. Позволяет определить, насколько выдача \"заточена\" под польователя\n",
    "* novelty (новизна) - как часто попадают в выдачу новые (холодные) элементы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашнее задание на метрики\n",
    "\n",
    "Даны два вектора - истинная история пользователя и объекты, которые считает релеватными ваша модель\n",
    "\n",
    "Вычислите\n",
    "\n",
    "* precision\n",
    "* recall\n",
    "* precision@5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "user_interactions = [47315, 30004, 36322,  8942, 30820,  6086,  9126,   332, 16289,\n",
    "       39106, 39335, 48506, 48654,  9234, 29935,  2678, 36202, 22636, 18007, 39328, 15414, 30016, 35601,\n",
    "    58409, 21313,   386, 16303, 4397, 19644, 51887, 21659, 36325, 53030,  7764, 50266, 58734, 53419, 24121,\n",
    "    50806, 36092,  8868, 28037, 36131, 13561, 16298, 27508, 41722, 30189, 46490,  2676, 43328, 781, 48397,\n",
    "    41369, 39324, 36381, 39635, 27710, 47837, 28525, 12024, 56604, 41664, 37387, 48507, 413, 33526, 20059,\n",
    "    49781, 56648, 16283, 50805, 34254, 39325, 59374, 22620,  8865, 27512, 13875, 30011,  7621,\n",
    "    10544, 28076, 29716, 30054, 20490, 29466, 16852, 39363, 34250, 7024, 33541,   263, 21267, 25690, 23020,\n",
    "    41368, 53414,  2681, 30201] \n",
    "\n",
    "user_recs = [\n",
    "    50820, 27781, 36131, 50812, 36092, 12024, 59155, 30042, 15414, 19882, 21659, 27849, 39328, 34240, 2681,\n",
    "    21267, 50126, 58560, 7764, 49781\n",
    "]\n",
    "\n",
    "# --- ВАШ КОД ТУТ ---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом уроке познакомились с метриками. Теперь вы можете отличать хорошие модели рекомендаций от плохих."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом модуле мы мознакомились с темой рекомендательных систем. Это область знаний, которую \"просто выучить, сложно понять\" - потому что с помощью простых алгоритмов ML можно сильно увеличить эффективность вашего бизнеса, но правильное применение этих методов к задаче построения рекомендательной системы - особое искусство, требующее хорошего понимания бизнес-области и знания специфических метрик систем ранжирования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
