{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализация наивного Байесовского классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>sms_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                           sms_text\n",
       "0  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "1   ham  U dun say so early hor... U c already then say...\n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...\n",
       "3  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
       "4   ham  Even my brother is not like to speak with me. ..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filename = 'data/sms_spam_collection.tar.gz'\n",
    "\n",
    "df = pd.read_csv(\n",
    "    filename,\n",
    "    compression='gzip',\n",
    "    header=1,\n",
    "    sep='\\t',\n",
    "    encoding='utf8',\n",
    "    names=['class', 'sms_text'],\n",
    "    error_bad_lines=False\n",
    ")\n",
    "\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>sms_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                           sms_text\n",
       "5566   ham               Will ü b going to esplanade fr home?\n",
       "5567   ham  Pity, * was in mood for that. So...any other s...\n",
       "5568   ham  The guy did some bitching but I acted like i'd...\n",
       "5569   ham                         Rofl. Its true to its name\n",
       "5570   NaN                                                NaN"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>sms_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                           sms_text\n",
       "5565  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5566   ham               Will ü b going to esplanade fr home?\n",
       "5567   ham  Pity, * was in mood for that. So...any other s...\n",
       "5568   ham  The guy did some bitching but I acted like i'd...\n",
       "5569   ham                         Rofl. Its true to its name"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(how='all')\n",
    "\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверяем, сколько у нас всего объектов в датасете"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5570 2\n"
     ]
    }
   ],
   "source": [
    "num_objects, num_features = df.shape\n",
    "print(num_objects, num_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Целевая переменная (target) в столбце `class`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    spam\n",
       "1     ham\n",
       "2     ham\n",
       "3    spam\n",
       "4     ham\n",
       "Name: class, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Демонстрация того, как получить булеву маску для датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1       False\n",
       "2       False\n",
       "3        True\n",
       "4       False\n",
       "        ...  \n",
       "5565     True\n",
       "5566    False\n",
       "5567    False\n",
       "5568    False\n",
       "5569    False\n",
       "Name: class, Length: 5570, dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SPAM_CLASS = 'spam'\n",
    "NOT_SPAM_CLASS = 'ham'\n",
    "\n",
    "df['class'] == SPAM_CLASS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Использование булевой маски для фильтрации датафрейма "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam sms: 747, not spam sms 4823\n"
     ]
    }
   ],
   "source": [
    "spam_sms_num = (df['class'] == SPAM_CLASS).sum()\n",
    "notspam_sms_num = (df['class'] == NOT_SPAM_CLASS).sum()\n",
    "\n",
    "print(f'spam sms: {spam_sms_num}, not spam sms {notspam_sms_num}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Задача\n",
    "\n",
    "считаем вероятности классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1341, 0.8659\n"
     ]
    }
   ],
   "source": [
    "# априорная вероятность класса спам\n",
    "p_spam = spam_sms_num / (spam_sms_num + notspam_sms_num)\n",
    "\n",
    "# априорная вероятность класса не спам\n",
    "p_notspam = notspam_sms_num / (spam_sms_num + notspam_sms_num)\n",
    "\n",
    "print(f'{p_spam:.4f}, {p_notspam:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример обработки текстовой информации - приводим к нижнему регистру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_word = 'Free'.lower()\n",
    "\n",
    "test_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply 08452810075over18's\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_example = df['sms_text'].values[0]\n",
    "\n",
    "sms_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пишем полезные сниппеты для трансформации текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "0123456789\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Free entry in  a wkly comp to win FA Cup final tkts st May  Text FA to  to receive entry questionstd txt rateTCs apply overs'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# удаляем знаки препинания и цифры\n",
    "import string\n",
    "\n",
    "print(string.punctuation)\n",
    "print(string.digits)\n",
    "\n",
    "sms_example = ''.join([\n",
    "    char \n",
    "    for char in sms_example \n",
    "    if (\n",
    "        char not in string.punctuation \n",
    "        and \n",
    "        char not in string.digits\n",
    "    )\n",
    "])\n",
    "\n",
    "sms_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'free entry in a wkly comp to win fa cup final tkts st may text fa to to receive entry questionstd txt ratetcs apply overs'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# приводим слова к нижнему регистру\n",
    "\n",
    "sms_example = ' '.join([\n",
    "    word.lower()\n",
    "    for word in sms_example.split()\n",
    "])\n",
    "\n",
    "sms_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объединяем сниппеты в функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "free entry in a wkly comp to win fa cup final tkts st may text fa to to receive entry questionstd txt ratetcs apply overs\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "\n",
    "def text_preprocess(sms_text: str) -> str:\n",
    "    \"\"\"Преобразование текста для анализа\"\"\"\n",
    "    text_no_punctuation = ''.join([\n",
    "        char \n",
    "        for char in sms_text \n",
    "        if (\n",
    "            char not in string.punctuation \n",
    "            and \n",
    "            char not in string.digits\n",
    "        )\n",
    "    ])\n",
    "    text_lowercase = ' '.join([\n",
    "        word.lower()\n",
    "        for word in text_no_punctuation.split()\n",
    "    ])\n",
    "    \n",
    "    return text_lowercase\n",
    "\n",
    "\n",
    "sms_example = df['sms_text'].values[0]\n",
    "\n",
    "print(text_preprocess(sms_example))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Трансформируем каждую строчку датафрейма"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>sms_text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>free entry in a wkly comp to win fa cup final ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>freemsg hey there darling its been weeks now a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>even my brother is not like to speak with me t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  class                                           sms_text  \\\n",
       "0  spam  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "1   ham  U dun say so early hor... U c already then say...   \n",
       "2   ham  Nah I don't think he goes to usf, he lives aro...   \n",
       "3  spam  FreeMsg Hey there darling it's been 3 week's n...   \n",
       "4   ham  Even my brother is not like to speak with me. ...   \n",
       "\n",
       "                                      processed_text  \n",
       "0  free entry in a wkly comp to win fa cup final ...  \n",
       "1        u dun say so early hor u c already then say  \n",
       "2  nah i dont think he goes to usf he lives aroun...  \n",
       "3  freemsg hey there darling its been weeks now a...  \n",
       "4  even my brother is not like to speak with me t...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.assign(\n",
    "    processed_text=df['sms_text'].apply(text_preprocess)\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>sms_text</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5565</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>this is the nd time we have tried contact u u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5566</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "      <td>will ü b going to esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>pity was in mood for that soany other suggestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>the guy did some bitching but i acted like id ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>rofl its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     class                                           sms_text  \\\n",
       "5565  spam  This is the 2nd time we have tried 2 contact u...   \n",
       "5566   ham               Will ü b going to esplanade fr home?   \n",
       "5567   ham  Pity, * was in mood for that. So...any other s...   \n",
       "5568   ham  The guy did some bitching but I acted like i'd...   \n",
       "5569   ham                         Rofl. Its true to its name   \n",
       "\n",
       "                                         processed_text  \n",
       "5565  this is the nd time we have tried contact u u ...  \n",
       "5566                will ü b going to esplanade fr home  \n",
       "5567  pity was in mood for that soany other suggestions  \n",
       "5568  the guy did some bitching but i acted like id ...  \n",
       "5569                          rofl its true to its name  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Задача\n",
    "\n",
    "Находим вероятность встретить слово в каждом из классов - это наша основная \"фича\" в наивном байесовском классификаторе"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(word=\"free\"|class=spam)=0.2664\n",
      "P(word=\"free\"|class=not_spam)=0.0137\n"
     ]
    }
   ],
   "source": [
    "# вероятность встретить слово в спам смс\n",
    "spam_messages = df[df['class'] == SPAM_CLASS]['processed_text'].tolist()\n",
    "spam_test_word_entries = 0\n",
    "for message in spam_messages:\n",
    "    if test_word in message:\n",
    "        spam_test_word_entries += 1\n",
    "\n",
    "\n",
    "# вероятность встретить слово в не-спам смс\n",
    "notspam_messages = df[df['class'] == NOT_SPAM_CLASS]['processed_text'].tolist()\n",
    "notspam_test_word_entries = 0\n",
    "for message in notspam_messages:\n",
    "    if test_word in message:\n",
    "        notspam_test_word_entries += 1\n",
    "\n",
    "        \n",
    "print(f'P(word=\"{test_word}\"|class=spam)={spam_test_word_entries/spam_sms_num:.4f}')\n",
    "print(f'P(word=\"{test_word}\"|class=not_spam)={notspam_test_word_entries/notspam_sms_num:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вывод\n",
    "\n",
    "слово \"free\" встречается в спам смс с вероятностью $26.6\\%$, а в не-спаме с вероятностью $1.3\\%$ - т.е. это слово является хорошим \"маркером\" спама"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Реализовать классификатор\n",
    "\n",
    "Аналогично тому, как посчитали вероятности встретить слово `free` в каждом классе (спам / не спам) \n",
    "* в функции `fit()` подсчитать такие вероятности для каждого слова\n",
    "* в функции `predict()` по формуле байеса (см. лекцию) вычислять вероятность принадлежности входного текста к каждому из классов\n",
    "\n",
    "Результат предсказания - класс, вероятность принадлежности к которому больше"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"имплементация наивного байесовского классификатора\"\"\"\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.labels = [NOT_SPAM_CLASS, SPAM_CLASS]\n",
    "        self.class_labels_proba = None  # априорная вероятность класса, словарь\n",
    "        self.prior_word_proba = None  # частоты фичей (токенов)\n",
    "        self.prediction = None  # выводить предсказания только по желанию\n",
    "    \n",
    "    def _set_labels_prior_proba(self, data: list, target: list) -> None:\n",
    "        \"\"\"Вычисление априорной вероятности классов\"\"\"\n",
    "        class_labels_amount = dict.fromkeys(self.labels, 0)\n",
    "        for target_type in target:\n",
    "            class_labels_amount[target_type] += 1  # кол-во элементов класса\n",
    "        \n",
    "        all_amount = len(data)\n",
    "        class_labels_proba = {}\n",
    "        for target_type, target_amount in class_labels_amount.items():\n",
    "            class_labels_proba.update({target_type: target_amount / all_amount})  # доля элементов класса\n",
    "        \n",
    "        self.class_labels_proba = class_labels_proba\n",
    "    \n",
    "    def _tokenize_text(self, text) -> list:\n",
    "        \"\"\"Функция, которая разобьёт входной текст на токены(слова)\"\"\"\n",
    "        return text_preprocess(text).split()\n",
    "    \n",
    "    def _set_word_prior_proba(self, data, target):\n",
    "        \"\"\"Вычисляем априорную вероятность токенов в классе\n",
    "        Заполняем словарь self.prior_word_proba[label][word]\n",
    "        \"\"\"\n",
    "        word_dict_by_class = dict.fromkeys(self.labels)\n",
    "        word_freq_by_class = dict.fromkeys(self.labels)\n",
    "        word_dict_all = defaultdict(int)\n",
    "        for target_type in target:\n",
    "            word_dict_by_class[target_type] = defaultdict(int)\n",
    "            word_freq_by_class[target_type] = defaultdict(int)\n",
    "\n",
    "        for target_type, message in zip(target, data):  # считаем кол-во слов:\n",
    "            for word in self._tokenize_text(message):\n",
    "                word_dict_by_class[target_type][word] += 1  # по классу\n",
    "                word_dict_all[word] += 1  # всего\n",
    "\n",
    "        all_amount = sum(v for k, v in word_dict_all.items())  # кол-во всех слов\n",
    "        for target_type in target:  # получаем долю слов в общем кол-ве\n",
    "            for word in word_dict_by_class[target_type]:\n",
    "                word_freq_by_class[target_type][word] = word_dict_by_class[target_type][word] / all_amount\n",
    "        \n",
    "        self.prior_word_proba = word_freq_by_class\n",
    "\n",
    "    def fit(self, data: list, target: list):\n",
    "        \"\"\"Обучение статистик по датасету\n",
    "\n",
    "        :param data: массив документов, каждый документ - объект типа str\n",
    "        :param target: массив меток объектов\n",
    "        \"\"\"\n",
    "        if not isinstance(data, list):\n",
    "            raise ValueError('Аргумент data должен иметь тип list')\n",
    "        if not isinstance(target, list):\n",
    "            raise ValueError('Аргумент target должен иметь тип list')\n",
    "        print('Данные инициализированы')\n",
    "        self._set_labels_prior_proba(data, target)\n",
    "        print(f'Априорные вероятности классов {self.class_labels_proba}')\n",
    "        self._set_word_prior_proba(data, target)\n",
    "        print('Обучили априорные вероятности слов')\n",
    "        \n",
    "\n",
    "    def _predict_proba(self, data: list) -> List[tuple]:\n",
    "        \"\"\"Предсказываем класс для текстовой смс\n",
    "\n",
    "        :param data: массив документов, для каждого из которых нужно предсказать метку\n",
    "        :return: вероятности для каждого из классов\n",
    "        \"\"\"\n",
    "        prediction = []\n",
    "        for obj in data:\n",
    "            posterior_class_proba = defaultdict(lambda: 1)\n",
    "            for token in self._tokenize_text(obj):\n",
    "                for label in self.labels:\n",
    "                    posterior_class_proba[label] *= self.prior_word_proba[label][token]\n",
    "            # сохраняем для каждой метки класса - сколько меток, таков и размер tuple\n",
    "            prediction.append(\n",
    "                tuple(\n",
    "                    posterior_class_proba[label] for label in self.labels\n",
    "                )\n",
    "            )\n",
    "        self.prediction = prediction\n",
    "        return prediction\n",
    "    \n",
    "    def predict(self, data) -> List[str]:\n",
    "        predict_labels = []\n",
    "        for proba in self._predict_proba(data):\n",
    "            predict_labels.append(self.labels[np.argmax(proba)])\n",
    "        return predict_labels\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Данные инициализированы\n",
      "Априорные вероятности классов {'ham': 0.8658886894075404, 'spam': 0.1341113105924596}\n",
      "Обучили априорные вероятности слов\n"
     ]
    }
   ],
   "source": [
    "naive_bayes = NaiveBayes()\n",
    "\n",
    "naive_bayes.fit(\n",
    "    data=df['sms_text'].values.tolist(),\n",
    "    target=df['class'].tolist()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово 'thank':\n",
      "p_ham = 0.000324 \n",
      "p_spam = 0.000012\n"
     ]
    }
   ],
   "source": [
    "proba = naive_bayes.prior_word_proba['ham']['thank'], naive_bayes.prior_word_proba['spam']['thank']\n",
    "print(\"Слово 'thank':\")\n",
    "print(f'p_ham = {proba[0]:.6f} \\np_spam = {proba[1]:.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Слово 'you':\n",
      "p_ham = 0.02210 \n",
      "p_spam = 0.00344\n"
     ]
    }
   ],
   "source": [
    "proba = naive_bayes.prior_word_proba['ham']['you'], naive_bayes.prior_word_proba['spam']['you']\n",
    "print(\"Слово 'you':\")\n",
    "print(f'p_ham = {proba[0]:.5f} \\np_spam = {proba[1]:.5f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказание метки класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "On the road so cant txt\n",
      "Predicted, Real: ham, ham\n",
      "\n",
      "Excellent! Are you ready to moan and scream in ecstasy?\n",
      "Predicted, Real: ham, ham\n",
      "\n",
      "Wen u miss someone, the person is definitely special for u..... But if the person is so special, why to miss them, just Keep-in-touch gdeve..\n",
      "Predicted, Real: ham, ham\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# рандомный объект датасета\n",
    "\n",
    "random_obj_ind = np.random.randint(low=0, high=num_objects, size=3)\n",
    "random_obj_list = df['sms_text'].values[random_obj_ind].tolist()\n",
    "random_target = df['class'][random_obj_ind].tolist()\n",
    "\n",
    "predicted_targets = naive_bayes.predict(random_obj_list)\n",
    "\n",
    "for i, msg in enumerate(random_obj_list):\n",
    "    print(f'\\n{msg}')\n",
    "    print(f'Predicted, Real: {predicted_targets[i]}, {random_target[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля правильных предсказаний: 0.996588868940754\n"
     ]
    }
   ],
   "source": [
    "correct_predictions = 0\n",
    "predictions = naive_bayes.predict(df['sms_text'].values.tolist())\n",
    "real_classes = df['class'].tolist()\n",
    "\n",
    "for num in range(len(predictions)):\n",
    "    if predictions[num] == real_classes[num]:\n",
    "        correct_predictions += 1\n",
    "        \n",
    "print(f'Доля правильных предсказаний: {correct_predictions / len(predictions)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0839765366399706e-33, 0.0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naive_bayes.prediction[20]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
